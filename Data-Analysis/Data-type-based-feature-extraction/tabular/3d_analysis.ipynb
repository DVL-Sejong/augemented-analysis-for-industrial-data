{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!yes | pip install trimesh==3.21.6\n!yes | pip install open3d==0.17.0\n!yes | pip install natsort==8.3.1","metadata":{"execution":{"iopub.status.busy":"2023-07-07T06:53:38.027580Z","iopub.execute_input":"2023-07-07T06:53:38.028047Z","iopub.status.idle":"2023-07-07T06:54:40.068239Z","shell.execute_reply.started":"2023-07-07T06:53:38.028014Z","shell.execute_reply":"2023-07-07T06:54:40.066704Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import sys \nprint(sys.version)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T07:03:02.476956Z","iopub.execute_input":"2023-07-07T07:03:02.478973Z","iopub.status.idle":"2023-07-07T07:03:02.488633Z","shell.execute_reply.started":"2023-07-07T07:03:02.478897Z","shell.execute_reply":"2023-07-07T07:03:02.486890Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]\n","output_type":"stream"}]},{"cell_type":"code","source":"from typing import Tuple\nfrom natsort import natsorted\nfrom tqdm import tqdm\n\nimport os\nimport json\nimport errno\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport IPython.display as IPd\n\nimport plotly.express as px\nimport plotly.graph_objs as go\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nimport trimesh\nimport open3d as o3d\n\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.svm import SVC","metadata":{"execution":{"iopub.status.busy":"2023-07-07T07:03:02.599531Z","iopub.execute_input":"2023-07-07T07:03:02.600843Z","iopub.status.idle":"2023-07-07T07:03:04.841603Z","shell.execute_reply.started":"2023-07-07T07:03:02.600804Z","shell.execute_reply":"2023-07-07T07:03:04.839962Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Jupyter environment detected. Enabling Open3D WebVisualizer.\n[Open3D INFO] WebRTC GUI backend enabled.\n[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n","output_type":"stream"}]},{"cell_type":"code","source":"seed = 42\n\nrandom.seed(seed)\nnp.random.seed(seed)\nos.environ[\"PYTHONHASHSEED\"] = str(seed)\n\no3d.utility.random.seed(seed)\n\ntorch.manual_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T07:03:08.894905Z","iopub.execute_input":"2023-07-07T07:03:08.895776Z","iopub.status.idle":"2023-07-07T07:03:08.918432Z","shell.execute_reply.started":"2023-07-07T07:03:08.895721Z","shell.execute_reply":"2023-07-07T07:03:08.915039Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x78cdca57f170>"},"metadata":{}}]},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/2023-ml-project3/modelnet10'\n\nDATA_PATH   = os.path.join(BASE_PATH, 'dataset')\nLABEL_PATH  = os.path.join(BASE_PATH, 'class2Label.json')\nSUBMIT_PATH = os.path.join(BASE_PATH, 'sample_submit.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-07-07T07:03:09.034913Z","iopub.execute_input":"2023-07-07T07:03:09.035475Z","iopub.status.idle":"2023-07-07T07:03:09.042441Z","shell.execute_reply.started":"2023-07-07T07:03:09.035434Z","shell.execute_reply":"2023-07-07T07:03:09.041268Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class_name_list = sorted(os.listdir(os.path.join(DATA_PATH, 'train')))\n\nscene_list = list()\n\nfor class_name in class_name_list:\n    off = random.choice(os.listdir(os.path.join(DATA_PATH, 'train', class_name)))\n    \n    mesh = trimesh.load(os.path.join(DATA_PATH, 'train', class_name, off))\n    \n    scene = trimesh.Scene()\n    \n    scene.add_geometry(mesh)\n    \n    scene_list.append(scene)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T07:03:11.388993Z","iopub.execute_input":"2023-07-07T07:03:11.390058Z","iopub.status.idle":"2023-07-07T07:03:12.076127Z","shell.execute_reply.started":"2023-07-07T07:03:11.390021Z","shell.execute_reply":"2023-07-07T07:03:12.074641Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for class_name, scene in zip(class_name_list, scene_list):\n    IPd.display(IPd.HTML(f\"<h4 style='text-align:center;'>{class_name}</h4>\"))\n    IPd.display(scene.show())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ModelNet10(Dataset):\n    def __init__(self, root: str, split: str, class2label:dict):\n        self.root = root\n        self.split = split.lower()\n        assert split in ['train', 'test']\n        \n        if class2label is not None:\n            self.class2label = class2label\n        \n        self.path, self.label = list(), list()\n        \n        if self.split == 'train':\n            self.classes = sorted(os.listdir(os.path.join(self.root, self.split)))\n            self.le = {self.classes[i]: self.class2label[self.classes[i]] for i in range(len(self.classes))}\n        \n            for class_name in self.classes:\n                class_path = os.path.join(self.root, self.split, class_name)\n\n                for off in os.listdir(class_path):\n                    if off.endswith('off'):\n                        self.path.append(os.path.join(class_path, off))\n                        self.label.append(self.le[class_name])\n                    else:\n                        raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), off)\n                        \n        elif self.split == 'test':\n            fname_list = natsorted(os.listdir(os.path.join(self.root, self.split)))\n            for fname in fname_list:\n                self.path.append(os.path.join(self.root, self.split, fname))\n            \n    def __getitem__(self, index):\n        if self.split == 'train':\n            return self.path[index], self.label[index]\n        elif self.split == 'test':\n            return self.path[index]\n    \n    def __len__(self):\n        return len(self.path)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T07:04:02.000843Z","iopub.execute_input":"2023-07-07T07:04:02.001341Z","iopub.status.idle":"2023-07-07T07:04:02.017661Z","shell.execute_reply.started":"2023-07-07T07:04:02.001300Z","shell.execute_reply":"2023-07-07T07:04:02.016401Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"with open(LABEL_PATH, 'r') as j:\n    class2label = json.load(j)\n    \ntrain_dataset = ModelNet10(root=DATA_PATH, split='train', class2label=class2label)\ntrain_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n\ntest_dataset = ModelNet10(root=DATA_PATH, split='test', class2label=None)\ntest_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T07:04:06.710173Z","iopub.execute_input":"2023-07-07T07:04:06.710610Z","iopub.status.idle":"2023-07-07T07:04:06.738640Z","shell.execute_reply.started":"2023-07-07T07:04:06.710579Z","shell.execute_reply":"2023-07-07T07:04:06.737717Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# 반복문을 통해 학습 데이터로더로부터 데이터 디렉토리(off)와 정수형 라벨(label)을 받음\nfor off, label in train_dataloader:\n    print(f'TRAIN DATALOADER\\npath: {off}\\nlabel: {label}\\n')\n    print(f'TRAIN DATALOADER\\npath: {off[0]}\\nlabel: {label.item()}'); break\n    \n# 반복문을 통해 평가 데이터로더로부터 데이터 디렉토리(off)를 받음\nfor off in test_dataloader:\n    print(f'\\nTEST  DATALODER\\npath: {off[0]}'); break","metadata":{"execution":{"iopub.status.busy":"2023-07-07T07:04:13.110032Z","iopub.execute_input":"2023-07-07T07:04:13.110450Z","iopub.status.idle":"2023-07-07T07:04:13.192688Z","shell.execute_reply.started":"2023-07-07T07:04:13.110421Z","shell.execute_reply":"2023-07-07T07:04:13.191425Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"TRAIN DATALOADER\npath: ('/kaggle/input/2023-ml-project3/modelnet10/dataset/train/bathtub/bathtub_0098.off',)\nlabel: tensor([0])\n\nTRAIN DATALOADER\npath: /kaggle/input/2023-ml-project3/modelnet10/dataset/train/bathtub/bathtub_0098.off\nlabel: 0\n\nTEST  DATALODER\npath: /kaggle/input/2023-ml-project3/modelnet10/dataset/test/0.off\n","output_type":"stream"}]},{"cell_type":"code","source":"def read_off(off: str) -> Tuple[np.array, np.array]:\n    with open(off, 'r') as f:\n        first_line = f.readline().strip()\n        if first_line != 'OFF':\n            raise ValueError('Not a valid OFF header')\n        \n        n_vertex, n_face, n_edge = map(int, f.readline().strip().split())\n        #print(n_vertex, n_face, n_edge)\n        vertices = list()\n        for _ in range(n_vertex):\n            vertex = list(map(float, f.readline().strip().split()))\n            vertices.append(vertex)\n        \n        faces = list()\n        for _ in range(n_face):\n            face = list(map(int, f.readline().strip().split()[1:]))\n            faces.append(face)\n        \n        # Vertex들의 정보를 담은 리스트(vertices)와 Face들의 정보를 담은 리스트(faces)를 각각 numpy array로 변환하여 튜플 형식으로 반환\n        return np.array(vertices), np.array(faces)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T07:20:37.091603Z","iopub.execute_input":"2023-07-07T07:20:37.092171Z","iopub.status.idle":"2023-07-07T07:20:37.105673Z","shell.execute_reply.started":"2023-07-07T07:20:37.092133Z","shell.execute_reply":"2023-07-07T07:20:37.103969Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# 3D 데이터 표현 방법 선택: 'point_cloud', 'voxel', 'mesh' 중 하나를 선택\nmethod = 'point_cloud'","metadata":{"execution":{"iopub.status.busy":"2023-07-07T07:20:37.233807Z","iopub.execute_input":"2023-07-07T07:20:37.235589Z","iopub.status.idle":"2023-07-07T07:20:37.243721Z","shell.execute_reply.started":"2023-07-07T07:20:37.235445Z","shell.execute_reply":"2023-07-07T07:20:37.241614Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def estimate_normal_vector_from_point_cloud(point_cloud, radius: int = None, max_nn: int = None) -> np.array:\n    pcd = o3d.geometry.PointCloud()\n\n    pcd.points = o3d.utility.Vector3dVector(point_cloud)\n    \n    search_param = o3d.geometry.KDTreeSearchParamHybrid(radius=radius, max_nn=max_nn)\n    pcd.estimate_normals(search_param=search_param)\n    \n    normal = np.asarray(pcd.normals)\n    return normal","metadata":{"execution":{"iopub.status.busy":"2023-07-07T07:20:37.372607Z","iopub.execute_input":"2023-07-07T07:20:37.373386Z","iopub.status.idle":"2023-07-07T07:20:37.380988Z","shell.execute_reply.started":"2023-07-07T07:20:37.373339Z","shell.execute_reply":"2023-07-07T07:20:37.379257Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def compute_histogram_of_normal_vector(normal_vector, n_bins: int = 10, n_range: tuple = (-1,1)):\n\n    hist_x, bin_edges_x = np.histogram(normal_vector[:, 0], bins=n_bins, range=n_range)\n    hist_y, bin_edges_y = np.histogram(normal_vector[:, 1], bins=n_bins, range=n_range)\n    hist_z, bin_edges_z = np.histogram(normal_vector[:, 2], bins=n_bins, range=n_range)\n\n    feature = np.concatenate((hist_x, hist_y, hist_z))\n\n    feature_normalized = feature / np.sum(feature)\n\n    return feature_normalized","metadata":{"execution":{"iopub.status.busy":"2023-07-07T07:20:38.699465Z","iopub.execute_input":"2023-07-07T07:20:38.700208Z","iopub.status.idle":"2023-07-07T07:20:38.709070Z","shell.execute_reply.started":"2023-07-07T07:20:38.700169Z","shell.execute_reply":"2023-07-07T07:20:38.707716Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"if method == 'point_cloud':\n\n    x_train_point_cloud, y_train_point_cloud = list(), list()\n    \n    pbar = tqdm(enumerate(train_dataloader, start=1))\n    for i, (off_, label_) in pbar:\n        off, label = off_[0], label_.item()\n        \n        point_cloud, a = read_off(off)\n       \n        normal_vector = estimate_normal_vector_from_point_cloud(point_cloud, radius=5, max_nn=30)\n        \n        training_feature = compute_histogram_of_normal_vector(normal_vector, n_bins=32, n_range=(-1, 1))\n        \n        x_train_point_cloud.append(training_feature)\n        y_train_point_cloud.append(label)\n\n        pbar.set_description(f'Processing: {os.path.basename(off)}\\tPercentage: {i / len(train_dataset) * 100:.1f}%')\n\n    # 학습 데이터와 학습 라벨을 numpy array 형식으로 변환\n    x_train_point_cloud = np.asarray(x_train_point_cloud)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T07:20:38.877591Z","iopub.execute_input":"2023-07-07T07:20:38.878026Z","iopub.status.idle":"2023-07-07T07:22:30.546584Z","shell.execute_reply.started":"2023-07-07T07:20:38.877993Z","shell.execute_reply":"2023-07-07T07:22:30.545179Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Processing: desk_0057.off\tPercentage: 100.0%: : 1000it [01:51,  8.96it/s]     \n","output_type":"stream"}]},{"cell_type":"code","source":"if method == 'point_cloud':\n    x_test_point_cloud = list()\n    \n    pbar = tqdm(enumerate(test_dataloader, start=1))\n    for i, (off_) in pbar:\n        off = off_[0]\n        \n        point_cloud, faces = read_off(off)\n        \n        normal_vector = estimate_normal_vector_from_point_cloud(point_cloud, radius=5, max_nn=30)\n        \n        feature = compute_histogram_of_normal_vector(normal_vector,n_bins=32, n_range=(-1, 1))\n        \n        x_test_point_cloud.append(feature)\n        \n        pbar.set_description(f'Processing: {os.path.basename(off)}\\tPercentage: {i / len(test_dataset) * 100:.1f}%')\n\n    # 평가 데이터를 numpy array 형식으로 변환\n    x_test_point_cloud = np.asarray(x_test_point_cloud)","metadata":{"execution":{"iopub.status.busy":"2023-07-07T07:22:30.549108Z","iopub.execute_input":"2023-07-07T07:22:30.549687Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Processing: 203.off\tPercentage: 68.0%: : 204it [00:18, 13.91it/s]","output_type":"stream"}]},{"cell_type":"markdown","source":"- SVM classification","metadata":{}},{"cell_type":"code","source":"print(f'Select Method is {method}')\n\nif method == 'point_cloud':\n    x_train, y_train = x_train_point_cloud, y_train_point_cloud\n    x_test = x_test_point_cloud\n\nelif method == 'voxel':\n    x_train, y_train = x_train_voxel, y_train_voxel\n    x_test = x_test_voxel\n\nelif method == 'mesh':\n    x_train, y_train = x_train_mesh, y_train_mesh\n    x_test = x_test_mesh\n    \nfrom sklearn.svm import SVC\nsvm = SVC(C=10, random_state=seed)\nsvm.fit(x_train, y_train)\nprint(sum(svm.predict(x_train) == y_train) / len(y_train)) #train set predict 정확도 체크\n\npred = svm.predict(x_test)\n\nsubmit = pd.read_csv(SUBMIT_PATH, index_col=0)\nsubmit['Label'] = pred\n\nsubmit.to_csv(f\"{method}_baseline.csv\")","metadata":{},"execution_count":null,"outputs":[]}]}