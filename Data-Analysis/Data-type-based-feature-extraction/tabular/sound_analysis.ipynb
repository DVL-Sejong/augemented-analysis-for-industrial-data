{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        continue\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-17T07:36:19.314984Z","iopub.execute_input":"2023-08-17T07:36:19.315405Z","iopub.status.idle":"2023-08-17T07:36:19.442454Z","shell.execute_reply.started":"2023-08-17T07:36:19.315368Z","shell.execute_reply":"2023-08-17T07:36:19.441145Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 랜덤 시드 고정\nimport random\nimport librosa\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport time\n\nseed = 42\n\nrandom.seed(seed)\nnp.random.seed(seed)\nos.environ[\"PYTHONHASHSEED\"] = str(seed)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:36:19.450034Z","iopub.execute_input":"2023-08-17T07:36:19.451394Z","iopub.status.idle":"2023-08-17T07:36:19.467646Z","shell.execute_reply.started":"2023-08-17T07:36:19.451347Z","shell.execute_reply":"2023-08-17T07:36:19.466067Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"rootpath = '***'","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:48:26.677728Z","iopub.execute_input":"2023-08-17T07:48:26.678912Z","iopub.status.idle":"2023-08-17T07:48:26.684779Z","shell.execute_reply.started":"2023-08-17T07:48:26.678855Z","shell.execute_reply":"2023-08-17T07:48:26.683321Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# 학습할 음악들의 장르 정답 csv 파일\ntrain_info_csv = pd.read_csv(rootpath + '/train_labels.csv')\n\n# 제출에 사용할 csv 파일\nsubmit = pd.read_csv(rootpath + '/submit.csv')\ntest_info_csv = submit['id']","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:48:26.829317Z","iopub.execute_input":"2023-08-17T07:48:26.829801Z","iopub.status.idle":"2023-08-17T07:48:26.845021Z","shell.execute_reply.started":"2023-08-17T07:48:26.829755Z","shell.execute_reply":"2023-08-17T07:48:26.843766Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# label\ntrain_info_csv['genre'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:36:19.761388Z","iopub.execute_input":"2023-08-17T07:36:19.762417Z","iopub.status.idle":"2023-08-17T07:36:19.779732Z","shell.execute_reply.started":"2023-08-17T07:36:19.762367Z","shell.execute_reply":"2023-08-17T07:36:19.778257Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"array(['rock', 'country', 'metal', 'hiphop', 'pop', 'classical', 'disco',\n       'reggae', 'blues', 'jazz'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"def extract_rhythm_features(file_path):\n    # 반환할 feature list 선언\n    feature = []\n    y, sr = librosa.load(file_path, sr=22050)\n    onset_envelope = librosa.onset.onset_strength(y=y, sr=sr)\n    \n    # autocorrelation tempogram\n    tempogram = librosa.feature.tempogram(onset_envelope=onset_envelope, sr=sr)  # (384, 1293)\n    #print(tempogram.shape)\n    tempogram_feature = np.abs(np.mean(tempogram, axis=1))   # (384, 1293) -> (384, ), 복소수를 없애기 위해 절대값 처\n    #print(tempogram_feature.shape)\n    \n    feature = tempogram_feature\n    \n    return feature","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:36:19.909177Z","iopub.execute_input":"2023-08-17T07:36:19.909832Z","iopub.status.idle":"2023-08-17T07:36:19.918751Z","shell.execute_reply.started":"2023-08-17T07:36:19.909780Z","shell.execute_reply":"2023-08-17T07:36:19.917040Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def extract_spectral_features(file_path):\n    # 반환할 feature list 선언\n    feature = []\n    y, sr = librosa.load(file_path, sr=22050)\n\n    spectrogram = np.abs(librosa.stft(y))\n    power_spectrogram = spectrogram ** 2\n    melspectrogram = librosa.feature.melspectrogram(S=power_spectrogram)\n    melspectrogram_db = librosa.power_to_db(melspectrogram)\n    \n    # chromagram\n    chromagram = librosa.feature.chroma_stft(S=power_spectrogram) # (12, 1293)\n    chromagram_feature = np.mean(chromagram, axis=1)  # (12, 1293) -> (12, )\n     \n    # mfcc\n    mfcc = librosa.feature.mfcc(S=melspectrogram_db)   # (20, 1293)\n    mfcc_feature = np.mean(mfcc, axis=1) # (20, )\n    \n    feature = np.concatenate((chromagram_feature, mfcc_feature))\n\n    return feature","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:36:21.256801Z","iopub.execute_input":"2023-08-17T07:36:21.257227Z","iopub.status.idle":"2023-08-17T07:36:21.267830Z","shell.execute_reply.started":"2023-08-17T07:36:21.257189Z","shell.execute_reply":"2023-08-17T07:36:21.266033Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def feature_loader(data_info, split=None, rootpath=None, domain=None):\n    split = split.upper()\n    info_dict = {}\n    \n    if split=='TRAIN':\n        train_path = os.path.join(rootpath, 'train')\n        file_list = data_info['id']\n        label_list = data_info['genre']\n        \n        for file, label in zip(tqdm(file_list), label_list):\n            # 손상된 wav파일 제외\n            if file == 'train_412.wav':\n                continue\n                \n            file_dict = {}     \n            file_dict['label'] = label\n            \n            file_path = os.path.join(train_path, file)\n            if domain == 'spectral':\n                features = extract_spectral_features(file_path)\n            elif domain == 'rhythm':\n                features = extract_rhythm_features(file_path)\n            else:\n                raise Exception(\"Check domain\")\n                \n            file_dict['features'] = features\n            info_dict[file] = file_dict\n        \n        return info_dict\n        \n    elif split=='TEST':\n        test_path = os.path.join(rootpath, 'test')\n        file_list = data_info\n        \n        for file in tqdm(file_list):\n            file_dict = {}\n            file_path = os.path.join(test_path, file)\n            \n            if domain == 'spectral':\n                features = extract_spectral_features(file_path)\n            elif domain == 'rhythm':\n                features = extract_rhythm_features(file_path)\n            else:\n                raise Exception(\"Check domain\")\n                \n            file_dict['features'] = features\n            info_dict[file] = file_dict\n            \n        return info_dict\n    \n    else:\n        raise Exception(\"Check split\")","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:36:21.391455Z","iopub.execute_input":"2023-08-17T07:36:21.391954Z","iopub.status.idle":"2023-08-17T07:36:21.409085Z","shell.execute_reply.started":"2023-08-17T07:36:21.391893Z","shell.execute_reply":"2023-08-17T07:36:21.407817Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\n\n# 'spectral' or 'rhythm'\ndomain = 'rhythm'\n\n# 선택한 domain의 feature 추출, dictionary 반환 받기\ntrain_data = feature_loader(train_info_csv, split='train', rootpath=rootpath, domain=domain)\ntest_data = feature_loader(test_info_csv, split='test', rootpath=rootpath, domain=domain) ","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:36:22.970201Z","iopub.execute_input":"2023-08-17T07:36:22.970763Z","iopub.status.idle":"2023-08-17T07:40:15.914859Z","shell.execute_reply.started":"2023-08-17T07:36:22.970711Z","shell.execute_reply":"2023-08-17T07:40:15.913196Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"100%|██████████| 800/800 [03:09<00:00,  4.22it/s]\n100%|██████████| 200/200 [00:43<00:00,  4.61it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"x_train = []\ny_train = []\n\nfor key in train_data.keys():\n    x_train.append(train_data[key]['features'])\n    y_train.append(train_data[key]['label'])\n    \nx_train = np.asarray(x_train)\ny_train = np.asarray(y_train) ","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:45:37.119766Z","iopub.execute_input":"2023-08-17T07:45:37.120471Z","iopub.status.idle":"2023-08-17T07:45:37.136146Z","shell.execute_reply.started":"2023-08-17T07:45:37.120419Z","shell.execute_reply":"2023-08-17T07:45:37.134829Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ny_train = le.fit_transform(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:45:51.377984Z","iopub.execute_input":"2023-08-17T07:45:51.378595Z","iopub.status.idle":"2023-08-17T07:45:51.455776Z","shell.execute_reply.started":"2023-08-17T07:45:51.378537Z","shell.execute_reply":"2023-08-17T07:45:51.454365Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"x_test = []\n\nfor key in test_data.keys():\n    x_test.append(test_data[key]['features'])\n    #print(test_data[key]['features'].shape)\n    \nx_test = np.asarray(x_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:46:08.548328Z","iopub.execute_input":"2023-08-17T07:46:08.549357Z","iopub.status.idle":"2023-08-17T07:46:08.557681Z","shell.execute_reply.started":"2023-08-17T07:46:08.549305Z","shell.execute_reply":"2023-08-17T07:46:08.556039Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state=seed)\nrfc.fit(x_train, y_train)\npred_rfc = rfc.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:46:25.433253Z","iopub.execute_input":"2023-08-17T07:46:25.433694Z","iopub.status.idle":"2023-08-17T07:46:27.261156Z","shell.execute_reply.started":"2023-08-17T07:46:25.433653Z","shell.execute_reply":"2023-08-17T07:46:27.259521Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"submit['genre'] = le.inverse_transform(pred_rfc)\nsubmit.to_csv(f'{domain}_feature_baseline.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:46:36.618448Z","iopub.execute_input":"2023-08-17T07:46:36.618953Z","iopub.status.idle":"2023-08-17T07:46:36.636241Z","shell.execute_reply.started":"2023-08-17T07:46:36.618891Z","shell.execute_reply":"2023-08-17T07:46:36.634511Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\ntrain_pred = rfc.predict(x_train)\n\nprint(f\"Accuracy score: {accuracy_score(y_train, train_pred)*100}\")\nprint(confusion_matrix(y_train, train_pred))","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:46:48.675028Z","iopub.execute_input":"2023-08-17T07:46:48.675513Z","iopub.status.idle":"2023-08-17T07:46:48.730057Z","shell.execute_reply.started":"2023-08-17T07:46:48.675473Z","shell.execute_reply":"2023-08-17T07:46:48.728529Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Accuracy score: 99.87484355444305\n[[80  0  0  0  0  0  0  0  0  0]\n [ 0 80  0  0  0  0  0  0  0  0]\n [ 0  0 80  0  0  0  0  0  0  0]\n [ 0  0  0 80  0  0  0  0  0  0]\n [ 0  0  0  0 80  0  0  0  0  0]\n [ 0  0  0  0  0 79  0  0  0  0]\n [ 0  0  0  0  0  0 79  0  0  1]\n [ 0  0  0  0  0  0  0 80  0  0]\n [ 0  0  0  0  0  0  0  0 80  0]\n [ 0  0  0  0  0  0  0  0  0 80]]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}