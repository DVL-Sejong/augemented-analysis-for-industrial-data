{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ekzms\\.conda\\envs\\cooling\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TimeGradEstimator(\n",
    "    input_size=int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    dropout_rate=0.1,\n",
    "    # target_dim = int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    "    lags_seq=[1],\n",
    "    scheduler=scheduler,\n",
    "    num_inference_steps=10,\n",
    "    prediction_length=dataset.metadata.prediction_length,\n",
    "    context_length=dataset.metadata.prediction_length,\n",
    "    freq=dataset.metadata.freq,\n",
    "    scaling=\"mean\",\n",
    "    trainer_kwargs=dict(max_epochs=50, accelerator=\"gpu\", devices=\"auto\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs={\n",
    "                \"freq\": self.freq,\n",
    "                \"context_length\": self.context_length,\n",
    "                \"prediction_length\": self.prediction_length,\n",
    "                \"scheduler\": self.scheduler,\n",
    "                \"num_inference_steps\": self.num_inference_steps,\n",
    "                \"input_size\": self.input_size,\n",
    "                \"num_feat_dynamic_real\": (\n",
    "                    1 + self.num_feat_dynamic_real + len(self.time_features)\n",
    "                ),\n",
    "                \"num_feat_static_real\": max(1, self.num_feat_static_real),\n",
    "                \"num_feat_static_cat\": max(1, self.num_feat_static_cat),\n",
    "                \"cardinality\": self.cardinality,\n",
    "                \"embedding_dimension\": self.embedding_dimension,\n",
    "                \"num_layers\": self.num_layers,\n",
    "                \"hidden_size\": self.hidden_size,\n",
    "                \"dropout_rate\": self.dropout_rate,\n",
    "                \"lags_seq\": self.lags_seq,\n",
    "                \"scaling\": self.scaling,\n",
    "                \"default_scale\": self.default_scale,\n",
    "                \"num_parallel_samples\": self.num_parallel_samples,\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ekzms\\.conda\\envs\\cooling\\lib\\site-packages\\torchaudio\\backend\\utils.py:67: UserWarning: No audio backend is available.\n",
      "  warnings.warn('No audio backend is available.')\n",
      "c:\\Users\\ekzms\\.conda\\envs\\cooling\\lib\\site-packages\\gluonts\\json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ekzms\\.conda\\envs\\cooling\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional, Tuple, Union\n",
    "from pts.util import lagged_sequence_values\n",
    "from gluonts.torch.util import repeat_along_dim, unsqueeze_expand\n",
    "from gluonts.torch.modules.feature import FeatureEmbedder\n",
    "from gluonts.torch.scaler import MeanScaler, NOPScaler, Scaler, StdScaler\n",
    "\n",
    "def prepare_rnn_input(\n",
    "        feat_static_cat: torch.Tensor,\n",
    "        feat_static_real: torch.Tensor,\n",
    "        past_time_feat: torch.Tensor,\n",
    "        past_target: torch.Tensor,\n",
    "        past_observed_values: torch.Tensor,\n",
    "        future_time_feat: torch.Tensor,\n",
    "        input_size : int,\n",
    "        future_target: Optional[torch.Tensor] = None,\n",
    "        cardinality: List[int] = [1],\n",
    "        embedding_dimension : int = 5,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor,]:\n",
    "        context = past_target[:, -12 :, ...]\n",
    "        observed_context = past_observed_values[:, -12 :, ...]\n",
    "        \n",
    "        scaler: Scaler = MeanScaler(\n",
    "                dim=1, keepdim=True, default_scale=0.0\n",
    "            )\n",
    "        \n",
    "        embedder = FeatureEmbedder(\n",
    "            cardinalities=cardinality,\n",
    "            embedding_dims=embedding_dimension,\n",
    "        )\n",
    "        input, loc, scale = scaler(context, observed_context)\n",
    "        future_length = future_time_feat.shape[-2]\n",
    "        if future_length > 1:\n",
    "            assert future_target is not None\n",
    "            input = torch.cat(\n",
    "                (input, (future_target[:, : future_length - 1, ...] - loc) / scale),\n",
    "                dim=1,\n",
    "            )\n",
    "        prior_input = (past_target[:, : -12, ...] - loc) / scale\n",
    "\n",
    "        lags = lagged_sequence_values([1], prior_input, input, dim=1)\n",
    "        time_feat = torch.cat(\n",
    "            (\n",
    "                past_time_feat[:, -12 + 1 :, ...],\n",
    "                future_time_feat,\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        embedded_cat = embedder(feat_static_cat)\n",
    "        log_abs_loc = (\n",
    "            loc.abs().log1p() if input_size == 1 else loc.squeeze(1).abs().log1p()\n",
    "        )\n",
    "        log_scale = scale.log() if input_size == 1 else scale.squeeze(1).log()\n",
    "\n",
    "        static_feat = torch.cat(\n",
    "            (embedded_cat, feat_static_real, log_abs_loc, log_scale),\n",
    "            dim=-1,\n",
    "        )\n",
    "        expanded_static_feat = unsqueeze_expand(\n",
    "            static_feat, dim=1, size=time_feat.shape[-2]\n",
    "        )\n",
    "\n",
    "        features = torch.cat((expanded_static_feat, time_feat), dim=-1)\n",
    "\n",
    "        return torch.cat((lags, features), dim=-1), loc, scale, static_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_rnn_input_ex = prepare_rnn_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "from gluonts.dataset.repository.datasets import dataset_recipes, get_dataset\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import MultivariateEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pts.model.tempflow import TempFlowEstimator\n",
    "from pts.model.time_grad import TimeGradEstimator\n",
    "from pts.model.transformer_tempflow import TransformerTempFlowEstimator\n",
    "from pts import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exchange_rate_nips, electricity_nips, traffic_nips, solar_nips, wiki-rolling_nips, ## taxi_30min is buggy still\n",
    "dataset = get_dataset(\"electricity_nips\", regenerate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grouper = MultivariateGrouper(max_target_dim=min(2000, int(dataset.metadata.feat_static_cat[0].cardinality)))\n",
    "dataset_train = train_grouper(dataset.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': array([[115.27613 , 115.27613 , 115.27613 , ...,  71.42857 ,  52.99539 ,\n",
       "           52.419353],\n",
       "         [175.53192 , 164.89362 , 154.78723 , ..., 128.7234  , 129.78723 ,\n",
       "          116.489365],\n",
       "         [ 31.993204,  31.28539 ,  31.568516, ...,  63.703285,  45.58324 ,\n",
       "           41.19479 ],\n",
       "         ...,\n",
       "         [ 90.3149  ,  93.01075 ,  90.31874 , ..., 139.51228 , 111.4593  ,\n",
       "          114.91551 ],\n",
       "         [114.57534 , 120.746574, 126.23288 , ..., 238.14383 , 137.887   ,\n",
       "          132.05821 ],\n",
       "         [ 47.912006,  46.234154,  47.53915 , ...,  90.23117 ,  66.74124 ,\n",
       "           59.470543]], dtype=float32),\n",
       "  'start': Period('2014-01-01 00:00', 'H'),\n",
       "  'feat_static_cat': array([0])}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pts.model.time_grad.lightning_module import TimeGradLightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DEISMultistepScheduler\n",
    "scheduler = DEISMultistepScheduler( num_train_timesteps=150, beta_end=0.1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.freq = freq\n",
    "self.prediction_length = prediction_length\n",
    "self.input_size = input_size\n",
    "self.scheduler = scheduler\n",
    "self.num_inference_steps = num_inference_steps\n",
    "self.context_length = (\n",
    "    context_length if context_length is not None else prediction_length\n",
    ")\n",
    "self.patience = patience\n",
    "\n",
    "self.num_layers = num_layers\n",
    "self.hidden_size = hidden_size\n",
    "self.lr = 1e-3\n",
    "self.weight_decay = weight_decay\n",
    "self.dropout_rate = dropout_rate\n",
    "self.num_feat_dynamic_real = num_feat_dynamic_real\n",
    "self.num_feat_static_cat = num_feat_static_cat\n",
    "self.num_feat_static_real = num_feat_static_real\n",
    "self.cardinality = (\n",
    "    cardinality if cardinality and num_feat_static_cat > 0 else [1]\n",
    ")\n",
    "self.embedding_dimension = embedding_dimension\n",
    "self.scaling = scaling\n",
    "self.default_scale = default_scale\n",
    "self.lags_seq = lags_seq\n",
    "self.time_features = (\n",
    "    time_features\n",
    "    if time_features is not None\n",
    "    else time_features_from_frequency_str(self.freq)\n",
    ")\n",
    "\n",
    "self.num_parallel_samples = num_parallel_samples\n",
    "self.batch_size = batch_size\n",
    "self.num_batches_per_epoch = num_batches_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    "hidden_size=64,\n",
    "num_layers=2,\n",
    "dropout_rate=0.1,\n",
    "# target_dim = int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    "lags_seq=[1],\n",
    "#scheduler=scheduler,\n",
    "num_inference_steps=10,\n",
    "prediction_length=dataset.metadata.prediction_length,\n",
    "context_length=dataset.metadata.prediction_length,\n",
    "freq=dataset.metadata.freq,\n",
    "scaling=\"mean\",\n",
    "trainer_kwargs=dict(max_epochs=50, accelerator=\"gpu\", devices=\"auto\"),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.time_feature import TimeFeature, time_features_from_frequency_str\n",
    "time_features = None\n",
    "time_features = (\n",
    "            time_features\n",
    "            if time_features is not None\n",
    "            else time_features_from_frequency_str('H')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinality = None\n",
    "num_feat_static_cat = 0\n",
    "cardinality = (\n",
    "            cardinality if cardinality and num_feat_static_cat > 0 else [1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "10 validation errors for TimeGradModelModel\nfreq\n  str type expected (type=type_error.str)\ncontext_length\n  value is not a valid integer (type=type_error.integer)\nprediction_length\n  value is not a valid integer (type=type_error.integer)\ninput_size\n  value is not a valid integer (type=type_error.integer)\nnum_layers\n  value is not a valid integer (type=type_error.integer)\nhidden_size\n  value is not a valid integer (type=type_error.integer)\ndropout_rate\n  value is not a valid float (type=type_error.float)\nlags_seq -> 0\n  value is not a valid integer (type=type_error.integer)\nscaling\n  str type expected (type=type_error.str)\nnum_inference_steps\n  value is not a valid integer (type=type_error.integer)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10016/651816320.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m TimeGradLightningModule(\n\u001b[0m\u001b[0;32m      2\u001b[0m             \u001b[1;31m# loss=loss,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ekzms\\.conda\\envs\\cooling\\lib\\site-packages\\gluonts\\core\\component.py\u001b[0m in \u001b[0;36minit_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__repr__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidated_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;31m# attach the Pydantic model as the attribute of the initializer wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ekzms\\.conda\\envs\\cooling\\lib\\site-packages\\pts\\model\\time_grad\\lightning_module.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_kwargs, lr, weight_decay, patience)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_hyperparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeGradModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_decay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ekzms\\.conda\\envs\\cooling\\lib\\site-packages\\gluonts\\core\\component.py\u001b[0m in \u001b[0;36minit_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"self\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             }\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPydanticModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnmargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;31m# merge nmargs, kwargs, and the model fields into a single dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ekzms\\.conda\\envs\\cooling\\lib\\site-packages\\pydantic\\main.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 10 validation errors for TimeGradModelModel\nfreq\n  str type expected (type=type_error.str)\ncontext_length\n  value is not a valid integer (type=type_error.integer)\nprediction_length\n  value is not a valid integer (type=type_error.integer)\ninput_size\n  value is not a valid integer (type=type_error.integer)\nnum_layers\n  value is not a valid integer (type=type_error.integer)\nhidden_size\n  value is not a valid integer (type=type_error.integer)\ndropout_rate\n  value is not a valid float (type=type_error.float)\nlags_seq -> 0\n  value is not a valid integer (type=type_error.integer)\nscaling\n  str type expected (type=type_error.str)\nnum_inference_steps\n  value is not a valid integer (type=type_error.integer)"
     ]
    }
   ],
   "source": [
    "TimeGradLightningModule(\n",
    "            # loss=loss,\n",
    "            lr=1e-3,\n",
    "            weight_decay=1e-8,\n",
    "            patience=10,\n",
    "            model_kwargs={\n",
    "                \"freq\": freq,\n",
    "                \"context_length\": context_length,\n",
    "                \"prediction_length\": prediction_length,\n",
    "                \"scheduler\": scheduler,\n",
    "                \"num_inference_steps\": num_inference_steps,\n",
    "                \"input_size\": input_size,\n",
    "                \"num_feat_dynamic_real\": (\n",
    "                    1 + 0 + len(time_features)\n",
    "                ),\n",
    "                \"num_feat_static_real\": max(1, 0),\n",
    "                \"num_feat_static_cat\": max(1, 0),\n",
    "                \"cardinality\": cardinality,\n",
    "                \"embedding_dimension\": None,\n",
    "                \"num_layers\": num_layers,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"dropout_rate\": dropout_rate,\n",
    "                \"lags_seq\": lags_seq,\n",
    "                \"scaling\": scaling,\n",
    "                \"default_scale\": 0.0,\n",
    "                \"num_parallel_samples\": 100,\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size: torch.Size([1, 24, 370])\n",
    "input_size: torch.Size([1, 24, 370])\n",
    "prior_input_size: torch.Size([1, 0, 370])\n",
    "lags_size: torch.Size([1, 24, 370])\n",
    "time_feat_size: torch.Size([1, 24, 5])\n",
    "static_feat_size: torch.Size([1, 742])\n",
    "expanded_static_feat_size: torch.Size([1, 24, 742])\n",
    "features_size: torch.Size([1, 24, 747])\n",
    "torch.Size([1, 24, 1117])\n",
    "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         ...,\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')\n",
    "------\n",
    "torch.Size([1, 24, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = torch.rand((140,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4495, 0.1000, 0.3259,  ..., 0.0753, 0.8908, 0.6085],\n",
       "        [0.2675, 0.3706, 0.5410,  ..., 0.6440, 0.7569, 0.1065],\n",
       "        [0.0845, 0.1099, 0.7057,  ..., 0.6930, 0.2216, 0.4199],\n",
       "        ...,\n",
       "        [0.7294, 0.7986, 0.0877,  ..., 0.9380, 0.1775, 0.2543],\n",
       "        [0.0922, 0.4064, 0.9166,  ..., 0.8525, 0.5120, 0.1626],\n",
       "        [0.5605, 0.3524, 0.6727,  ..., 0.9560, 0.4364, 0.9747]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.eye(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 20])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "supports = [A,A]\n",
    "weights = torch.nn.Parameter(torch.FloatTensor(2*3*20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): the number of subscripts in the equation (3) does not match the number of dimensions (2) for operand 1 and no ellipsis was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10016/2987080875.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0msupport_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupport_ks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msupport\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msupport_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mx_g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nm,bmc->bnc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msupport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maaa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mx_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# B, N, 2 * cheb_k * dim_in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mx_gconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bni,io->bno'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# b, N, dim_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ekzms\\.conda\\envs\\cooling\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36meinsum\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: einsum(): the number of subscripts in the equation (3) does not match the number of dimensions (2) for operand 1 and no ellipsis was given"
     ]
    }
   ],
   "source": [
    "aaa = torch.rand((24,20))\n",
    "A = torch.eye(20)\n",
    "supports = [A,A]\n",
    "weights = torch.nn.Parameter(torch.FloatTensor(2*3*20, 20))\n",
    "x_g = []        \n",
    "support_set = []\n",
    "for support in supports:\n",
    "    support_ks = [torch.eye(support.shape[0]).to(support.device), support]\n",
    "    for k in range(2, 3):\n",
    "        support_ks.append(torch.matmul(2 * support, support_ks[-1]) - support_ks[-2]) \n",
    "    support_set.extend(support_ks)\n",
    "for support in support_set:\n",
    "    x_g.append(torch.einsum(\"nm,bmc->bnc\", support, aaa))\n",
    "x_g = torch.cat(x_g, dim=-1) # B, N, 2 * cheb_k * dim_in\n",
    "x_gconv = torch.einsum('bni,io->bno', x_g, weights)  # b, N, dim_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = torch.rand((24,20))\n",
    "A = torch.rand(20, 20)\n",
    "B = torch.rand(20, 20)\n",
    "supports = [A, B]\n",
    "weights = torch.nn.Parameter(torch.FloatTensor(2 * 3 * 20, 20))\n",
    "support_set = []\n",
    "for support in supports:\n",
    "    support_ks = [torch.eye(support.shape[0]).to(support.device), support]\n",
    "    for k in range(2, 3):\n",
    "        support_ks.append(torch.matmul(2 * support, support_ks[-1]) - support_ks[-2]) \n",
    "    support_set.extend(support_ks)\n",
    "\n",
    "#x_g = torch.cat(x_g, dim=-1)  # B, N, 2 * cheb_k * dim_in\n",
    "\n",
    "# Perform matrix multiplication using torch.matmul\n",
    "x_gconv = torch.matmul(x_g, weights)  # b, N, dim_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 20])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([20, 20])\n"
     ]
    }
   ],
   "source": [
    "x_g = []  \n",
    "for support in support_set:\n",
    "    print(support.size())\n",
    "    x_g.append(torch.matmul(aaa, support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_g = torch.cat(x_g, dim=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gconv = torch.matmul(x_g, weights)  # b, N, dim_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 20])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_gconv.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cooling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
