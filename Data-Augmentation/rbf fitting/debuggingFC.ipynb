{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import torch.optim as optim\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class FeatureRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(FeatureRegression, self).__init__()\n",
    "        self.build(input_size)\n",
    "\n",
    "    def build(self, input_size):\n",
    "        self.W = Parameter(torch.Tensor(input_size, input_size))\n",
    "        self.b = Parameter(torch.Tensor(input_size))\n",
    "\n",
    "        m = torch.ones(input_size, input_size) - torch.eye(input_size, input_size)\n",
    "        self.register_buffer('m', m)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.W.size(0))\n",
    "        self.W.data.uniform_(-stdv, stdv)\n",
    "        if self.b is not None:\n",
    "            self.b.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_h = F.linear(x, self.W * Variable(self.m), self.b)\n",
    "        return z_h\n",
    "\n",
    "class TemporalDecay(nn.Module):\n",
    "    def __init__(self, input_size, output_size, diag = False):\n",
    "        super(TemporalDecay, self).__init__()\n",
    "        self.diag = diag\n",
    "\n",
    "        self.build(input_size, output_size)\n",
    "\n",
    "    def build(self, input_size, output_size):\n",
    "        self.W = Parameter(torch.Tensor(output_size, input_size))\n",
    "        self.b = Parameter(torch.Tensor(output_size))\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        if self.diag == True:\n",
    "            assert(input_size == output_size)\n",
    "            m = torch.eye(input_size, input_size)\n",
    "            self.register_buffer('m', m)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.W.size(0))\n",
    "        self.W.data.uniform_(-stdv, stdv)\n",
    "        if self.b is not None:\n",
    "            self.b.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, d):\n",
    "        gamma = self.relu(F.linear(d, self.W, self.b))\n",
    "        gamma = torch.exp(-gamma)\n",
    "        return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCRBFGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(FCRBFGRU, self).__init__()\n",
    "\n",
    "        self.RBFtemp_decay_h = TemporalDecay(input_size, output_size = hidden_size, diag = False)\n",
    "        self.RBftemp_decay_x = TemporalDecay(input_size, input_size, diag = True)\n",
    "        self.RBFtemp_decay_r = TemporalDecay(input_size, input_size, diag = True)\n",
    "\n",
    "        self.temp_decay_h = TemporalDecay(input_size, output_size = hidden_size, diag = False)\n",
    "        self.temp_decay_x = TemporalDecay(input_size, input_size, diag = True)\n",
    "\n",
    "        self.concat_temp_decay_x = TemporalDecay(input_size, input_size, diag = True)\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.build()\n",
    "\n",
    "    def build(self):\n",
    "        self.RBFoutput_layer = nn.Linear(self.hidden_size, self.input_size, bias=True)\n",
    "        self.output_layer = nn.Linear(self.hidden_size, self.input_size, bias=True)\n",
    "        \n",
    "        self.z_layer = FeatureRegression(self.input_size)\n",
    "        self.beta_layer = nn.Linear(self.input_size * 2, self.input_size)\n",
    "        self.grucell = nn.GRUCell(self.input_size * 2, self.hidden_size)\n",
    "\n",
    "        self.RBFbeta_layer = nn.Linear(self.input_size * 2, self.input_size)\n",
    "        self.RBFgrucell = nn.GRUCell(self.input_size * 2, self.hidden_size)\n",
    "\n",
    "        self.concoat_beta_layer = nn.Linear(self.input_size * 2, self.input_size)\n",
    "        self.concat_layer = nn.Linear(self.input_size * 2, self.input_size)\n",
    "        self.hidden_dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.diag = torch.ones(self.input_size,self.input_size).cuda() - torch.eye(self.input_size,self.input_size).cuda()\n",
    "        self.W = torch.nn.parameter.Parameter(torch.Tensor(self.input_size, self.input_size))\n",
    "        self.linear2 = nn.Linear(self.input_size, self.input_size, bias = True)\n",
    "        self.linear3 = nn.Linear(self.input_size, self.input_size, bias = True)\n",
    "        self.V = torch.nn.parameter.Parameter(torch.Tensor(self.input_size, self.input_size))\n",
    "        \n",
    "\n",
    "    def loss(self, hat, y, m):\n",
    "        return torch.sum(torch.abs((y - hat)) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "    \n",
    "    def forward(self, input):\n",
    "        values = input[:,0,::]\n",
    "        delta = input[:,1,::]\n",
    "        masks = input[:,2,::]\n",
    "        rbfs = input[:,3,::]\n",
    "\n",
    "        RBF_hid = torch.zeros((values.size(0), self.hidden_size)).cuda()\n",
    "        hid = torch.zeros((values.size(0), self.hidden_size)).cuda()\n",
    "\n",
    "        rbf_loss = 0.0\n",
    "        gru_loss = 0.0\n",
    "        concat_loss = 0.0\n",
    "\n",
    "        imputations = []\n",
    "        c_hat_list = []\n",
    "        for i in range(values.size(1)):\n",
    "\n",
    "            v = values[:,i,:]\n",
    "            d = delta[:,i,:]\n",
    "            m = masks[:,i,:]\n",
    "            r = rbfs[:,i,:]\n",
    "\n",
    "            # RBF temporal\n",
    "            RBF_gamma_x = self.RBftemp_decay_x(d)\n",
    "            \n",
    "            RBF_gamma_h = self.RBFtemp_decay_h(d)\n",
    "\n",
    "            r_hat = self.RBFtemp_decay_r(r)\n",
    "            rbf_loss += torch.sum(torch.abs(v - r_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "            \n",
    "            RBF_x_hat = self.RBFoutput_layer(RBF_hid)\n",
    "            rbf_loss += torch.sum(torch.abs(v - RBF_x_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "            RBF_beta_weight = torch.cat([RBF_gamma_x, m], dim = 1)\n",
    "            RBF_beta = torch.sigmoid(self.RBFbeta_layer(RBF_beta_weight))\n",
    "\n",
    "            RBF_c_hat = RBF_beta * r_hat + (1 - RBF_beta) * RBF_x_hat\n",
    "            rbf_loss += torch.sum(torch.abs(v - RBF_c_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "            RBF_c_c = m * v + (1 - m) * RBF_c_hat\n",
    "\n",
    "            RBF_gru_input = torch.cat([RBF_c_c, m], dim = 1)\n",
    "            \n",
    "            # RBF GRU cell\n",
    "            RBF_hid = RBF_hid * RBF_gamma_h\n",
    "            self.hidden_dropout(RBF_hid)\n",
    "            RBF_hid = self.RBFgrucell(RBF_gru_input, RBF_hid)\n",
    "\n",
    "            # MGRU\n",
    "            gamma_x = self.temp_decay_x(d)\n",
    "            gamma_h = self.temp_decay_h(d)\n",
    "\n",
    "            x_hat = self.output_layer(hid)\n",
    "            gru_loss += torch.sum(torch.abs(v - x_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "            x_c = m * v + (1 - m) * x_hat\n",
    "            \n",
    "            z_hat = self.z_layer(x_c)\n",
    "            gru_loss += torch.sum(torch.abs(v - z_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "            \n",
    "            beta_weight = torch.cat([gamma_x, m], dim = 1)\n",
    "            beta = torch.sigmoid(self.beta_layer(beta_weight))\n",
    "\n",
    "            c_hat = beta * z_hat + (1 - beta) * x_hat\n",
    "            gru_loss += torch.sum(torch.abs(v - c_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "            c_c = m * v + (1 - m) * c_hat\n",
    "\n",
    "            gru_input = torch.cat([c_c, m], dim = 1)\n",
    "            \n",
    "            # GRU cell\n",
    "            hid = hid * gamma_h\n",
    "            hid = self.grucell(gru_input, hid)\n",
    "\n",
    "            # concat_RBF_GRU\n",
    "\n",
    "            concat_gamma_x = self.concat_temp_decay_x(d)\n",
    "\n",
    "            RG = torch.cat([RBF_c_hat, c_hat], dim = 1)\n",
    "            concat = self.concat_layer(RG)\n",
    "            concat_loss += torch.sum(torch.abs(v - concat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "            concat_c = m * v + (1 - m) * concat\n",
    "            concat_z_hat = self.linear2(concat_c) + torch.matmul(v, self.diag * self.W)\n",
    "\n",
    "            concat_loss += torch.sum(torch.abs(v - concat_z_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "            concoat_beta_weight = torch.cat([concat_gamma_x, m], dim = 1)\n",
    "            concat_beta = torch.sigmoid(self.concoat_beta_layer(concoat_beta_weight))\n",
    "\n",
    "            concat_c_hat = concat_beta * concat_z_hat + (1 - concat_beta) * concat\n",
    "            concat_loss += torch.sum(torch.abs(v - concat_c_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "            concoat_c_c = m * v + (1 - m) * concat_c_hat\n",
    "\n",
    "            h_t = torch.matmul(concoat_c_c, self.V)\n",
    "  \n",
    "            imputation_X = self.linear3(h_t)\n",
    "\n",
    "            concat_loss += torch.sum(torch.abs(v - imputation_X) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "            imputation_X_c = m * v + (1 - m) * imputation_X\n",
    "            imputations.append(imputation_X_c.unsqueeze_(1))\n",
    "\n",
    "            c_hat_list.append(imputation_X.unsqueeze(1))\n",
    "        \n",
    "\n",
    "        x_loss = rbf_loss + gru_loss + concat_loss\n",
    "\n",
    "        c_hat_list = torch.cat(c_hat_list, dim = 1)\n",
    "        imputations = torch.cat(imputations, dim = 1)\n",
    "\n",
    "        return imputations, x_loss, c_hat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 36\n",
    "hidden_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RBFoutput_layer = nn.Linear(hidden_size, input_size, bias=True)\n",
    "output_layer = nn.Linear(hidden_size, input_size, bias=True)\n",
    "\n",
    "z_layer = FeatureRegression(input_size)\n",
    "beta_layer = nn.Linear(input_size * 2, input_size)\n",
    "grucell = nn.GRUCell(input_size * 2, hidden_size)\n",
    "\n",
    "RBFbeta_layer = nn.Linear(input_size * 2, input_size)\n",
    "RBFgrucell = nn.GRUCell(input_size * 2, hidden_size)\n",
    "\n",
    "concoat_beta_layer = nn.Linear(input_size * 2, input_size)\n",
    "concat_layer = nn.Linear(input_size * 2, input_size)\n",
    "hidden_dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "diag = torch.ones(input_size,input_size) - torch.eye(input_size,input_size)\n",
    "W = torch.nn.parameter.Parameter(torch.Tensor(input_size, input_size))\n",
    "linear2 = nn.Linear(input_size, input_size, bias = True)\n",
    "linear3 = nn.Linear(input_size, input_size, bias = True)\n",
    "V = torch.nn.parameter.Parameter(torch.Tensor(input_size, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBFtemp_decay_h = TemporalDecay(input_size, output_size = hidden_size, diag = False)\n",
    "RBftemp_decay_x = TemporalDecay(input_size, input_size, diag = True)\n",
    "RBFtemp_decay_r = TemporalDecay(input_size, input_size, diag = True)\n",
    "\n",
    "temp_decay_h = TemporalDecay(input_size, output_size = hidden_size, diag = False)\n",
    "temp_decay_x = TemporalDecay(input_size, input_size, diag = True)\n",
    "\n",
    "concat_temp_decay_x = TemporalDecay(input_size, input_size, diag = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import missing_data_rbf, eval_model, eval_bi_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/\"+\"pm25_missing.csv\").drop([\"datetime\"], axis = 1)\n",
    "dataset = missing_data_rbf(df, \"air_1000_0.05_time.csv\", 64, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for data in dataset:\n",
    "    if c == 0:\n",
    "        input = data\n",
    "    c +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = input[:,0,::]\n",
    "delta = input[:,1,::]\n",
    "masks = input[:,2,::]\n",
    "rbfs = input[:,3,::]\n",
    "\n",
    "RBF_hid = torch.zeros((values.size(0), hidden_size))\n",
    "hid = torch.zeros((values.size(0), hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = values[:,0,:]\n",
    "d = delta[:,0,:]\n",
    "m = masks[:,0,:]\n",
    "r = rbfs[:,0,:]\n",
    "rbf_loss = 0.0\n",
    "# RBF temporal\n",
    "RBF_gamma_x = RBftemp_decay_x(d)\n",
    "\n",
    "RBF_gamma_h = RBFtemp_decay_h(d)\n",
    "\n",
    "r_hat = RBFtemp_decay_r(r)\n",
    "rbf_loss += torch.sum(torch.abs(v - r_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "RBF_x_hat = RBFoutput_layer(RBF_hid)\n",
    "rbf_loss += torch.sum(torch.abs(v - RBF_x_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "RBF_beta_weight = torch.cat([RBF_gamma_x, m], dim = 1)\n",
    "RBF_beta = torch.sigmoid(RBFbeta_layer(RBF_beta_weight))\n",
    "\n",
    "RBF_c_hat = RBF_beta * r_hat + (1 - RBF_beta) * RBF_x_hat\n",
    "rbf_loss += torch.sum(torch.abs(v - RBF_c_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "RBF_c_c = m * v + (1 - m) * RBF_c_hat\n",
    "\n",
    "RBF_gru_input = torch.cat([RBF_c_c, m], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3426, 0.4037, 0.0880, 0.3042, 0.5413, 0.5409, 0.7487, 0.2959, 0.4872,\n",
       "        0.3634, 0.3295, 0.3762, 0.7436, 0.5878, 0.6051, 0.2241, 0.2420, 0.3545,\n",
       "        0.6326, 0.4130, 0.6317, 0.5260, 0.3214, 0.4381, 0.2434, 0.5335, 0.6288,\n",
       "        0.4104, 0.7181, 0.2662, 0.5824, 0.4076, 0.4526, 0.3790, 0.6003, 0.4115],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RBF_c_hat[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0457, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MGRU\n",
    "gru_loss = 0.0\n",
    "gamma_x = temp_decay_x(d)\n",
    "gamma_h = temp_decay_h(d)\n",
    "\n",
    "x_hat = output_layer(hid)\n",
    "gru_loss += torch.sum(torch.abs(v - x_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "x_c = m * v + (1 - m) * x_hat\n",
    "\n",
    "z_hat = z_layer(x_c)\n",
    "gru_loss += torch.sum(torch.abs(v - z_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "beta_weight = torch.cat([gamma_x, m], dim = 1)\n",
    "beta = torch.sigmoid(beta_layer(beta_weight))\n",
    "\n",
    "c_hat = beta * z_hat + (1 - beta) * x_hat\n",
    "gru_loss += torch.sum(torch.abs(v - c_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "c_c = m * v + (1 - m) * c_hat\n",
    "\n",
    "gru_input = torch.cat([c_c, m], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1691, -0.3117, -0.0144,  ...,  0.1093, -0.2849,  0.3670],\n",
       "        [ 0.0107, -0.0603,  0.0208,  ...,  0.0133,  0.0015,  0.0251],\n",
       "        [-0.0157, -0.0072,  0.0683,  ...,  0.1284,  0.1019,  0.0204],\n",
       "        ...,\n",
       "        [ 0.0301,  0.1064,  0.1902,  ...,  0.1319,  0.1425,  0.0457],\n",
       "        [-0.1753, -0.1091, -0.3963,  ..., -0.3496, -0.5075,  0.2824],\n",
       "        [-0.0336, -0.0377,  0.0830,  ...,  0.0933,  0.0820,  0.0337]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import MGRU,BiMGRU, train_MGRU, train_BiMGRU, RBF_MGRU, BiRBFMGRU, FCRBFGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_RBF_GRU\n",
    "concat_loss = 0.0\n",
    "concat_gamma_x = concat_temp_decay_x(d)\n",
    "\n",
    "RG = torch.cat([RBF_c_hat, c_hat], dim = 1)\n",
    "concat = concat_layer(RG)\n",
    "concat_loss += torch.sum(torch.abs(v - concat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "concat_c = m * v + (1 - m) * concat\n",
    "concat_z_hat = linear2(concat_c) + torch.matmul(v, diag * W)\n",
    "\n",
    "concat_loss += torch.sum(torch.abs(v - concat_z_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "concoat_beta_weight = torch.cat([concat_gamma_x, m], dim = 1)\n",
    "concat_beta = torch.sigmoid(concoat_beta_layer(concoat_beta_weight))\n",
    "\n",
    "concat_c_hat = concat_beta * concat_z_hat + (1 - concat_beta) * concat\n",
    "concat_loss += torch.sum(torch.abs(v - concat_c_hat) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "concoat_c_c = m * v + (1 - m) * concat_c_hat\n",
    "\n",
    "h_t = torch.matmul(concoat_c_c, V)\n",
    "\n",
    "imputation_X = linear3(h_t)\n",
    "\n",
    "concat_loss += torch.sum(torch.abs(v - imputation_X) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "imputation_X_c = m * v + (1 - m) * imputation_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.4496, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCRBFGRU(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.0481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.6245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.4391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.2512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.9974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.5441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.3478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11.0907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11.8521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.6244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(13.4261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.9333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(15.7016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.4978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17.2324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17.9841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(18.7472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19.5264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(20.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(20.9988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.7491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(22.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(23.2457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(23.9835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(24.7296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(25.5302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(26.2730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(27.0317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(27.8048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.6473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(29.4259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(30.2232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(31.0333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(31.8740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(32.6538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(33.4498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(34.2583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.0981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.8862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(36.6846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(37.4934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(38.3621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(39.1843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(40.0127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(40.8554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(41.6756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.4421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(43.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(44.0079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(44.8419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(45.6106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(46.3988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(47.1942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.0232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.8028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(49.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(50.3846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(51.2423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(52.0552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(52.8766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(53.7000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(54.5686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(55.3779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(56.2027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(57.0341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(57.8732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(58.6586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(59.4544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(60.2565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(61.0460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(61.7899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(62.5406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(63.2992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(64.1297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(64.9107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(65.6998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(66.4975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(67.2599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(67.9625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(68.6840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(69.4131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(70.2203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(70.9633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(71.7254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(72.5035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(73.3009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(74.0308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(74.7809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(75.5449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(76.3327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(77.0585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(77.8017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(78.5575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(79.3275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(80.0463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(80.7775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(81.5163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(82.3274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(83.0741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(83.8364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(84.6147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(85.3680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(86.0667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(86.7807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(87.5049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(88.2514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(88.9420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(89.6479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(90.3608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(91.1058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(91.7978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(92.5046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(93.2182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(93.9296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(94.5991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(95.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(95.9568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(96.6669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(97.3224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(97.9924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(98.6689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(99.4176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.1109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.8209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.5360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.2207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.8664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(103.5189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.1705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.8822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(105.5591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(106.2405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(106.9214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.7311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(108.4741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(109.2398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(110.0113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(110.7766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.4873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(112.2128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(112.9441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(113.7179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.4327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.1642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.9032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(116.7096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(117.4479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(118.2073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(118.9784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(119.7260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(120.4041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(121.1034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(121.8169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(122.5304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(123.1863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(123.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(124.5404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(125.2829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(125.9687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(126.6654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(127.3745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(128.0411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(128.6696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(129.3039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(129.9427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(130.6720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(131.3540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(132.0454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(132.7376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(133.4969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(134.2023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(134.9155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(135.6331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(136.3445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(137.0082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(137.6824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(138.3570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(139.0683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(139.7403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(140.4166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(141.0971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(141.8134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(142.4886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(143.1705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(143.8590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(144.5942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(145.2951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(146.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(146.7039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(147.4350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(148.1271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(148.8264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(149.5271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(150.2907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(151.0220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(151.7572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(152.4893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(153.2290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(153.9179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(154.6220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(155.3342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(156.0728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(156.7711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(157.4808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(158.1931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(158.9628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(159.6787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(160.4077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(161.1496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(161.9056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(162.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(163.3285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(164.0567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(164.7924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(165.4701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(166.1691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(166.8737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(167.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(168.3914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(169.1374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(169.8951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(170.6492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(171.3512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(172.0707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(172.7907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(173.5525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(174.2622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(174.9867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(175.7191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(176.4811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(177.1870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(177.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(178.6405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(179.4127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(180.1160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(180.8434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(181.5804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(182.3682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(183.0822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(183.8251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184.5797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(185.3976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(186.1307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(186.8992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187.6822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(188.4593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(189.1600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(189.8920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(190.6364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.3113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.9214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.5560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.2198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.9630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.6260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.3084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.0188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.4006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.0722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.7650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11.5077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.1673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.8481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(13.5536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.3048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.9617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(15.6497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.3627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17.1330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17.8136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(18.5228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19.2560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19.9857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(20.6263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.2911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(22.7212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(23.3682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(24.0434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(24.7474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(25.5087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(26.1860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(26.8874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(27.6156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.4117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(29.1156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(29.8490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(30.6164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(31.4239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(32.1434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(32.8871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(33.6692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(34.4533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.1556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.8768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(36.6309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(37.3861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(38.0644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(38.7636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(39.4919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(40.2459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(40.9250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(41.6236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.3476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(43.1169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(43.8052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(44.5147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(45.2532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(45.9963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(46.6642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(47.3536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.0662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.8403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(49.5408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(50.2570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(51.0025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(51.7625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(52.4611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(53.1722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(53.9084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(54.7216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(55.4692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(56.2294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(57.0155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(57.8076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(58.5360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(59.2807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(60.0460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(60.8697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(61.6119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(62.3792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(63.1749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(64.0069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(64.7555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(65.5322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(66.3349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(67.1648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(67.9043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(68.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(69.4685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(70.2801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(71.0216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(71.7811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(72.5647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(73.3735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(74.0923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(74.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(75.6086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(76.4037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(77.1369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(77.8852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(78.6539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(79.4388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(80.1374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(80.8642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(81.6268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(82.4151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(83.1138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(83.8389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(84.5973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(85.3948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(86.1028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(86.8356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(87.6049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(88.4122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(89.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(89.8832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(90.6643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(91.4681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(92.1718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(92.9086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(93.6821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(94.4822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(95.1947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(95.9321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(96.7059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(97.4931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(98.1946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(98.9230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(99.6853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.4994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.2365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.9923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.7801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(103.5903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.3293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(105.0840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(105.8717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(106.6700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.3872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(108.1234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(108.8937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(109.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(110.3540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.0650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(112.5903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(113.3115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.0503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.8147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.6460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(116.3985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(117.1709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(117.9738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(118.7608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(119.4639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(120.1906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(120.9419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(121.7652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(122.4906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(123.2455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(124.0301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(124.8217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(125.5229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(126.2469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(127.0045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(127.8213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(128.5483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(129.2993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(130.0837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(130.8810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(131.6041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(132.3452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(133.1106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(133.9714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(134.7481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(135.5454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(136.3710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(137.2091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(137.9528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(138.7275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(139.5314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(140.3324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(141.0556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(141.8003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(142.5674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(143.3106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(143.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(144.6864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(145.4066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(146.2567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(147.0362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(147.8368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(148.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(149.4425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(150.1576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(150.8925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(151.6517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(152.4714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(153.2091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(153.9729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(154.7673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(155.6263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(156.4008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(157.2001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(158.0303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(158.7894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(159.4711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(160.1750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(160.9071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(161.6533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(162.3300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(163.0229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(163.7396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(164.4944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(165.1746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(165.8728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(166.5976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(167.3463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(168.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(168.7122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(169.4313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(170.1452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(170.7916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(171.4541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(172.1384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(172.8951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(173.5571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(174.2463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(174.9662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(175.7074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(176.3645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(177.0436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(177.7467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(178.5426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(179.2494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(179.9790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(180.7405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(181.5272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(182.2208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(182.9402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(183.6942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184.4888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(185.1779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(185.8992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(186.6556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187.4271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(188.0997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(188.8019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(189.5367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.8446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.0194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.7540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.5237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.2156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.9579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.5658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.7975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11.3889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.0242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.9365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(13.7298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.5463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(15.4264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.4356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17.3049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(18.2099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19.1817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(20.2628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.1799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(22.1446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(23.1821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(24.2244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(25.0896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(26.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(26.9995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.0453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.9116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(29.8364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(30.8404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(31.9029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(32.7661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(33.6779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(34.6948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(36.6285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(37.5565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(38.5757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(39.6109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(40.4722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(41.3639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.3581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(43.2111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(43.9306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(44.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(45.4957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(46.4437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(47.2365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.0593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.9674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(49.8920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(50.7061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(51.5218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(52.4157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(53.2608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(54.0159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(54.7762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(55.6008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(56.3877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(57.0797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(57.7786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(58.5358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(59.3694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(60.0851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(60.8138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(61.6155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(62.4530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(63.1608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(63.8866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(64.6888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(65.5996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(66.3517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(67.1459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(68.0298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(68.9515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(69.7058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(70.5087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(71.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(72.4540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(73.3061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(74.2176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(75.2292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(76.0061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(76.6517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(77.3337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(78.0736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(79.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(80.2822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(81.3357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(82.4917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(83.7624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(84.7781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(85.8673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(87.0793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(88.3717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(89.4142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(90.5282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(91.7515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(92.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(93.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(94.2943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(95.2007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(96.1971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(97.0272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(97.8897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(98.8426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.3927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.7044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(103.0647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.5283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(106.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.2641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(108.5578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(109.9530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.4073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(112.6368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(113.9171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.3024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(116.9797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(118.3760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(119.8483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(121.4493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(122.9129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(124.1371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(125.4271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(126.8186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(128.2876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(129.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(130.8927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(132.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(133.9673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(135.4041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(136.9006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(138.4994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(139.9443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(141.2137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(142.5208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(143.8990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(145.0753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(146.0770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(147.1281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(148.2416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(149.2384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(150.1806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(151.1082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(152.0572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(152.7821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(153.4331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(154.0946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(154.7847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(155.5516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(156.3063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(157.0283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(157.7759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(158.4777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(159.1326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(159.7858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(160.4705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(161.2133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(161.8682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(162.5510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(163.2680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(163.9438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(164.5298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(165.1464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(165.7977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(166.5184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(167.1249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(167.7699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(168.4700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(169.2151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(169.8621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(170.5466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(171.2760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(172.0376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(172.6794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(173.3618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(174.1100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(174.8798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(175.5396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(176.2286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(176.9775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(177.7626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(178.4892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(179.2308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(180.0030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(180.7450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(181.4751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(182.1956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(182.9211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(183.6887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184.3889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(185.0991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(185.8509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(186.6018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187.2668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(187.9522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(188.6987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(189.4955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(190.1690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(190.8846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(191.6737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(192.4624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(193.1160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(193.8074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(194.5700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(195.3630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(196.0347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(196.7476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(197.5077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(198.3101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(198.9911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(199.7115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(200.4851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(201.3062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(201.9868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(202.7183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(203.5083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(204.3429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(205.0254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(205.7658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(206.5653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(207.4799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(208.2692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(209.0997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(209.9705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(210.8727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(211.6545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(212.4735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(213.3376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(214.2908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(215.1149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(215.9771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(216.9006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(217.7805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(218.5475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(219.3448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(220.1946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(221.1066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(221.8717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(222.6865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(223.5668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(224.3981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(225.0996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(225.8472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(226.6542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(227.4352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(228.1479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(228.8773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(229.6405, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1684.5130615234375:   0%|          | 1/1000 [00:02<49:07,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.3160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.9910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.6395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.3554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.0725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.2792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.9624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.2389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.8489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.5135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11.2392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11.8468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(13.1821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(13.9227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.5310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(15.1774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(15.8855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.6108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17.2145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17.8515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(18.5459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19.2535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(20.4591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.1388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.8602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(22.4571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(23.0886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(23.7859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(24.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(25.1906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(25.8610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(26.5986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(27.3716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.0125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.6890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(29.4349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(30.2322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(30.8869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(31.5783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(32.3461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(33.1148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(33.7521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(34.4248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.1690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.9442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(36.5798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(37.2533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(37.9991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(38.7470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(39.3746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(40.0296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(40.7485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(41.4908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.1242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.7819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(43.4986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(44.2101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(44.8219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(45.4526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(46.1383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(46.7985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(47.3708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(47.9553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.5943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(49.2731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(49.8623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(50.4650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(51.1215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(51.7943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(52.3753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(52.9725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(53.6249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(54.3226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(54.9150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(55.5301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(56.1999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(56.8925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(57.4776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(58.0892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(58.7591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(59.4068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(59.9526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(60.5256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(61.1524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(61.8700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(62.4587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(63.0817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(63.7723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(64.4839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(65.0726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(65.6915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(66.3793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(67.0980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(67.6889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(68.3110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(69.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(69.6917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(70.2698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(70.8735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(71.5434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(72.2072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(72.7683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(73.3531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(73.9982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(74.7324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(75.3444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(75.9851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(76.6885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(77.4326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(78.0465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(78.6922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(79.4065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(80.1580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(80.7777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(81.4302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(82.1520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(82.9166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(83.5376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(84.1985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(84.9318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(85.7100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(86.3420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(87.0153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(87.7596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(88.5290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(89.1637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(89.8366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(90.5748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(91.3716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(92.0361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(92.7365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(93.5031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(94.3504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(95.0433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(95.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(96.5914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(97.3760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(98.0126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(98.6933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(99.4474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.2052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.8497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.5191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.2491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.9955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(103.6062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.2542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.9710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(105.6848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(106.2713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(106.8925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.5815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(108.2841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(108.8567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(109.4649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(110.1377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(110.8609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.4586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(112.0876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(112.7768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(113.4560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.0237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.6202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.2725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.9926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(116.5919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(117.2243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(117.9121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(118.6676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(119.2923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(119.9481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(120.6639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(121.3684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(121.9537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(122.5724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(123.2482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(123.9729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(124.5736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(125.2072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(125.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(126.6325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(127.2408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(127.8797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(128.5789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(129.2914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(129.9077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(130.5462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(131.2400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(131.9860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(132.6202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(133.2834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(134.0069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(134.7785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(135.4357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(136.1197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(136.8671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(137.6220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(138.2483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(138.9117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(139.6463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(140.3913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(141.0145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(141.6718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(142.3934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(143.1228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(143.7257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(144.3591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(145.0653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(145.7582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(146.3317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(146.9327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(147.6054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(148.3194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(148.9086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(149.5297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(150.2256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(150.9702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(151.5787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(152.2230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(152.9457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(153.6227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(154.1835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(154.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(155.4326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(156.1666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(156.7601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(157.3915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(158.0976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(158.8004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(159.3833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(159.9964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(160.6762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(161.4274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(162.0350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(162.6862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(163.4093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(164.1636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(164.7678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(165.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(166.1466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(166.9143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(167.5144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(168.1684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(168.9034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(169.6656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(170.2710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(170.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(171.6591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.3309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.3846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.9587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.5678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.2532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.0251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.6452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.3007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.0310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.8083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.0904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.8240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11.5941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.2090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(13.5804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.3546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.9638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(15.6157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.3416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17.1401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17.7736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(18.4497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19.1971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19.9667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(20.5732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.2177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.9395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(22.7251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(23.3448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(24.0075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(24.7472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(25.5480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(26.1814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(26.8561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(27.6102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.4401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(29.0987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(29.8024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(30.5868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(31.4114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(32.0714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(32.7696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(33.5503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(34.3769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.0511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.7524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(36.5345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(37.2984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(37.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(38.5832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(39.3088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(40.0986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(40.7291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(41.3980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.1399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.9312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(43.5761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(44.2530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(44.9962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(45.8310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(46.5130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(47.2292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.0171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.9295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(49.6573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(50.4285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(51.2886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(52.1490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(52.8388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(53.5661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(54.3799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(55.2735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(55.9990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(56.7592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(57.6054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(58.5207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(59.2590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(60.0400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(60.9076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(61.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(62.4991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(63.2514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(64.0936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(65.0479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(65.7934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(66.5948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(67.4979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(68.4223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(69.1506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(69.9301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(70.8028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(71.7314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(72.4831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(73.2767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(74.1549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(75.0404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(75.7514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(76.5052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(77.3364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(78.2332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(78.9667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(79.7333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(80.5789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(81.4328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(82.1062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(82.8257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(83.6373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(84.4871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(85.1638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(85.8817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(86.6860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(87.5297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(88.2128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(88.9295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(89.7292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(90.5357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(91.2105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(91.9106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(92.6801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(93.4767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(94.1162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(94.7904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(95.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(96.3643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(97.0262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(97.7210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(98.4983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(99.2454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(99.8691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.5171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.0268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.6926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(103.3806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.1372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.9517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(105.6253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(106.3258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.0987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.8940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(108.5525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(109.2335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(109.9860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(110.7546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.4030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(112.0722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(112.8054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(113.6083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.2758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.9712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.7359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(116.5546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(117.2329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(117.9367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(118.7160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(119.4752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(120.1108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(120.7714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(121.4939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(122.2931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(122.9302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(123.6071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(124.3600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(125.0991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(125.7100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(126.3488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(127.0521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(127.8362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(128.4750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(129.1475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(129.8909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(130.6650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(131.3048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(131.9740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(132.7056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(133.5373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(134.2189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(134.9341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(135.7184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(136.5069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(137.1493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(137.8280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(138.5757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(139.3337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(139.9668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(140.6251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(141.3473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(142.0701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(142.6824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(143.3177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(144.0089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(144.7986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(145.4639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(146.1553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(146.9055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(147.6333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(148.2507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(148.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(149.5845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(150.3463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(150.9684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(151.6248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(152.3539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(153.1548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(153.8123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(154.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(155.2659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(156.0205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(156.6339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(157.2804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(158.0004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(158.7652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(159.3890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(160.0475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(160.7767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(161.5149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(162.1118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(162.7442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(163.4455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(164.1960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(164.8033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(165.4447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(166.1578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(166.9113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(167.5271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(168.1738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(168.8895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(169.6524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(170.2609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(170.9088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(171.6298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(172.4107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(173.0347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(173.6985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(174.4315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(175.2239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(175.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(176.5162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(177.2627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(178.0537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(178.6749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(179.3410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(180.0879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(180.8885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(181.5088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(182.1775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(182.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(183.6717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184.2590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(184.8853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(185.5853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.1407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.5596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.4546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.3932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.0757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.8332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.7212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.3879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.8664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11.3996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.0453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.9168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(13.5464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.2348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(15.0619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(15.9271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.5764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17.2746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(18.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19.0030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19.6678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(20.3903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.2519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(22.1201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(22.7672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(23.4595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(24.2819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(25.1767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(25.8165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(26.5222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(27.3653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.2936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.9353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(29.6501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(30.5213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(31.4273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(32.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(32.7740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(33.6252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(34.4784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.1279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.8080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(36.6120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(37.4742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(38.1391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(38.8314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(39.6478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(40.4749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(41.1187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(41.8004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.5835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(43.4760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(44.1290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(44.8390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(45.6867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(46.5942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(47.2488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(47.9720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.8365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(49.6730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(50.3101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(51.0009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(51.7898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(52.6706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(53.3211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(54.0336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(54.8685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(55.6863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(56.3660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(57.0752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(57.8533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(58.6320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(59.2487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(59.9163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(60.6716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(61.3507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(61.9106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(62.4962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(63.1579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(63.7950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(64.2705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(64.7983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(65.4210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(66.0476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(66.5019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(67.0086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(67.6177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(68.2757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(68.7496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(69.2791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(69.9025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(70.5602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(71.0041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(71.5179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(72.1537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(72.7865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(73.2312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(73.7327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(74.3424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(74.9758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(75.4155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(75.9152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(76.5342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(77.1558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(77.5911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(78.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(78.6954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(79.2877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(79.6999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(80.1647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(80.7451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(81.3520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(81.7856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(82.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(82.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(83.4527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(83.8820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(84.3574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(84.9410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(85.5105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(85.9170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(86.3660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(86.9133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(87.4954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(87.9293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(88.3989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(88.9602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(89.5579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(89.9933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(90.4678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(91.0405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(91.6435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(92.0751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(92.5604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(93.1340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(93.7682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(94.2315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(94.7433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(95.3485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(95.9595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(96.4108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(96.9063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(97.4840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(98.0670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(98.5050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(98.9823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(99.5452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.1743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.6275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.1411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.7425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.3476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.7724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(103.2576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(103.8270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.3649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.7567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(105.1898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(105.7033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(106.2569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(106.6592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.1056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.6449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(108.1608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(108.5457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(108.9690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(109.4690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(110.0159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(110.4309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(110.8805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.4041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.9031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(112.3092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(112.7290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(113.2090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(113.7523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.1930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.6566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.1958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.7345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(116.1799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(116.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(117.1678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(117.6626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(118.1022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(118.5431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(119.0572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(119.5874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(120.0255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(120.4886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(121.0171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(121.6606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(122.2064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(122.7677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(123.3854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(123.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(124.5179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(125.0558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(125.6559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(126.2535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(126.7542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(127.2818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(127.8753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(128.5424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(129.0842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(129.6480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(130.2802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(130.8893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(131.3967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(131.9296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(132.5142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(133.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(133.6076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(134.1354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(134.7073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(135.2576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(135.7194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(136.2004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(136.7161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(137.2489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(137.7006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(138.1699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(138.6859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(139.2196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(139.6808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(140.1544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(140.6697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(141.1416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(141.5881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(142.0218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(142.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(142.9847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(143.4197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(143.8579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(144.3582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(144.8739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(145.2806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(145.7086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(146.2141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(146.7870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(147.1951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(147.6550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(148.1980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(148.7976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(149.2233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(149.7173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(150.3079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(150.8793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(151.2933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(151.7663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(152.3182, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1472.85693359375:   0%|          | 2/1000 [00:05<47:53,  2.88s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.7855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.3777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.0797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.8189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.9540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.6438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.3494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.8915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.4653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.1280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.8800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11.4410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.0411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.7416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(13.4947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.0465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.6415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(15.3409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.6903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17.3060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(18.0233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(18.7894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19.3430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19.9429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(20.6479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.4071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.9621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(22.5633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(23.2669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(24.0680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(24.6530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(25.2837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(26.0192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(26.8198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(27.4053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.0360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.7768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(29.5964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(30.1959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(30.8413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(31.5989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(32.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(32.9266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(33.5324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(34.2355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(34.9626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.5096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(36.0930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(36.7736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(37.5009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(38.0527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(38.6356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(39.3109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(39.9925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(40.5244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(41.0798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(41.7196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.4582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(43.0227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(43.6187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(44.3095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(45.0477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(45.6187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(46.2179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(46.9065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(47.6477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.2187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.8182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(49.5113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(50.2451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(50.8144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(51.4127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(52.0984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(52.9250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(53.5388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(54.2022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(54.9694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(55.7611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(56.3453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(56.9796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(57.7140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(58.5087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(59.0961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(59.7358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(60.4748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(61.2934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(61.8935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(62.5450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(63.3044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(64.1354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(64.7504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(65.4118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(66.1838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(67.0115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(67.6112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(68.2629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(69.0254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(69.8416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(70.4485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(71.0985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(71.8546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(72.5986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(73.1515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(73.7478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(74.4450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(75.2727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(75.8830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(76.5412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(77.3085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(78.1251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(78.7314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(79.3778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(80.1326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(80.9550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(81.5766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(82.2341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(83.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(83.8808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(84.5207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(85.2115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(86.0252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(86.8979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(87.5369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(88.2236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(89.0285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(89.8553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(90.4637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(91.1217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(91.8891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(92.7732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(93.4301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(94.1363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(94.9543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(95.8755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(96.5466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(97.2718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(98.1208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(98.9700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(99.6081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(100.2922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.0830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(101.8517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(102.4632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(103.1022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(103.8293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(104.6194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(105.2063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(105.8392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(106.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.3368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(107.9227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(108.5426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(109.2594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(109.9779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(110.5233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(111.7760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(112.5320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(113.1027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(113.7127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(114.4154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.0870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(115.6035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(116.1536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(116.7870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(117.5379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(118.1013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(118.7077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(119.4127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(120.1922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(120.7807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(121.4066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(122.1287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(122.8776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(123.4426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(124.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(124.7528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(125.5201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(126.0927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(126.7083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(127.4308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(128.1927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(128.7688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(129.3825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(130.0961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(130.8067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(131.3717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(131.9662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(132.6388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(133.4193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(134.0120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(134.6460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(135.3771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(136.1552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(136.7703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(137.4131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(138.1434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(138.9126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(139.4955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(140.1193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(140.8462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(141.6093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(142.2078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(142.8356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(143.5589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(144.2984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(144.8662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(145.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(146.1623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(146.8684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(147.4122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(147.9850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(148.6517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(149.3460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(149.8739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(150.4386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(151.0926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(151.8262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(152.3812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(152.9738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(153.6627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(154.3603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(154.8951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(155.4652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(156.1207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(156.9056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(157.4675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(158.0817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(158.8058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(159.5560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(160.1144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(160.7186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(161.4196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(162.2449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(162.8296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(163.4723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(164.2338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(165.0423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(165.6023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(166.2275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(166.9774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(167.8096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(168.3777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(169.0130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(169.7795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(170.5519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(171.1029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(171.7079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(172.4298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.7415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.4843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.6840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.2212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.5992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.1146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.6789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.3402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.0619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.5708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.1218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.7749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(10.5024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11.5927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.2490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(12.9963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(13.5337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.1124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14.7895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(15.5276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.0651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(16.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(17.3129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(18.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(18.5090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19.0448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19.6776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(20.4046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(20.9291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(21.4907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(22.1589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(22.8999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(23.4229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(23.9897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(24.6667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(25.4479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(26.0129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(26.6215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(27.3406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28.6476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(29.2350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(29.9324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(30.7253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(31.3054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(31.9175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(32.6467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(33.4259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(33.9907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(34.5960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(35.3083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(36.0842, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1472.85693359375:   0%|          | 2/1000 [00:07<58:47,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36.6369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(37.2330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(37.9387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(38.7456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(39.3375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(39.9724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(40.7090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(41.4802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.0688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(42.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(43.3900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(44.1757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(44.7555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(45.3704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(46.0962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(46.8544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(47.4222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.0197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(48.7161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(49.4625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(50.0281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(50.6200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(51.3140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(52.0109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(52.5550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(53.1118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(53.7567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(54.4602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(54.9870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(55.5409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(56.1976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(56.9366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(57.4646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(58.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(58.7079, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chanyoung\\Desktop\\RBFmissing\\debuggingFC.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chanyoung/Desktop/RBFmissing/debuggingFC.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m FCRBFGRU(input_size, hidden_size)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chanyoung/Desktop/RBFmissing/debuggingFC.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m loss_list \u001b[39m=\u001b[39m train_MGRU(model, \u001b[39m0.001\u001b[39;49m, \u001b[39m1000\u001b[39;49m, dataset, device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chanyoung/Desktop/RBFmissing/debuggingFC.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m Nonscale_imputataion \u001b[39m=\u001b[39m eval_model(model,\u001b[39m\"\u001b[39m\u001b[39mair_1000_0.05_time.csv\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mpm25_ground.csv\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mpm25_missing.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\chanyoung\\Desktop\\RBFmissing\\models\\model.py:515\u001b[0m, in \u001b[0;36mtrain_MGRU\u001b[1;34m(model, lr, epochs, dataset, device)\u001b[0m\n\u001b[0;32m    513\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m    514\u001b[0m     x_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m--> 515\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    517\u001b[0m     batch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m x_loss\n\u001b[0;32m    518\u001b[0m progress\u001b[39m.\u001b[39mset_description(\u001b[39m\"\u001b[39m\u001b[39mloss: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(batch_loss))\n",
      "File \u001b[1;32mc:\\Users\\chanyoung\\anaconda3\\envs\\cooling\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\chanyoung\\Desktop\\RBFmissing\\models\\model.py:417\u001b[0m, in \u001b[0;36mFCRBFGRU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    414\u001b[0m RBF_beta_weight \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([RBF_gamma_x, m], dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m    415\u001b[0m RBF_beta \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mRBFbeta_layer(RBF_beta_weight))\n\u001b[1;32m--> 417\u001b[0m RBF_c_hat \u001b[39m=\u001b[39m RBF_beta \u001b[39m*\u001b[39m r_hat \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m RBF_beta) \u001b[39m*\u001b[39m RBF_x_hat\n\u001b[0;32m    418\u001b[0m rbf_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39mabs(v \u001b[39m-\u001b[39m RBF_c_hat) \u001b[39m*\u001b[39m m) \u001b[39m/\u001b[39m (torch\u001b[39m.\u001b[39msum(m) \u001b[39m+\u001b[39m \u001b[39m1e-5\u001b[39m)\n\u001b[0;32m    420\u001b[0m RBF_c_c \u001b[39m=\u001b[39m m \u001b[39m*\u001b[39m v \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m m) \u001b[39m*\u001b[39m RBF_c_hat\n",
      "File \u001b[1;32mc:\\Users\\chanyoung\\anaconda3\\envs\\cooling\\lib\\site-packages\\torch\\_tensor.py:31\u001b[0m, in \u001b[0;36m_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     30\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     32\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\chanyoung\\anaconda3\\envs\\cooling\\lib\\site-packages\\torch\\_tensor.py:604\u001b[0m, in \u001b[0;36mTensor.__rsub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m    603\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m\u001b[39m__rsub__\u001b[39m, (\u001b[39mself\u001b[39m, other), \u001b[39mself\u001b[39m, other)\n\u001b[1;32m--> 604\u001b[0m \u001b[39mreturn\u001b[39;00m _C\u001b[39m.\u001b[39;49m_VariableFunctions\u001b[39m.\u001b[39;49mrsub(\u001b[39mself\u001b[39;49m, other)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = FCRBFGRU(input_size, hidden_size)\n",
    "loss_list = train_MGRU(model, 0.001, 1000, dataset, device)\n",
    "Nonscale_imputataion = eval_model(model,\"air_1000_0.05_time.csv\",\"pm25_ground.csv\",\"pm25_missing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cooling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
