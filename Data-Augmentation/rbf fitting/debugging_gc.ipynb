{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import style\n",
    "style.use('seaborn-whitegrid')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint\n",
    "\n",
    "def lorenz(x, t, F):\n",
    "    '''Partial derivatives for Lorenz-96 ODE.'''\n",
    "    p = len(x)\n",
    "    dxdt = np.zeros(p)\n",
    "    for i in range(p):\n",
    "        dxdt[i] = (x[(i+1) % p] - x[(i-2) % p]) * x[(i-1) % p] - x[i] + F\n",
    "\n",
    "    return dxdt\n",
    "\n",
    "def simulate_lorenz_96(p, T, F=10.0, delta_t=0.1, sd=0.1, burn_in=1000,\n",
    "                       seed=0):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # Use scipy to solve ODE.\n",
    "    x0 = np.random.normal(scale=0.01, size=p)\n",
    "    t = np.linspace(0, (T + burn_in) * delta_t, T + burn_in)\n",
    "    X = odeint(lorenz, x0, t, args=(F,))\n",
    "    X += np.random.normal(scale=sd, size=(T + burn_in, p))\n",
    "\n",
    "    # Set up Granger causality ground truth.\n",
    "    GC = np.zeros((p, p), dtype=int)\n",
    "    for i in range(p):\n",
    "        GC[i, i] = 1\n",
    "        GC[i, (i + 1) % p] = 1\n",
    "        GC[i, (i - 1) % p] = 1\n",
    "        GC[i, (i - 2) % p] = 1\n",
    "\n",
    "    return X[burn_in:], GC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np, GC = simulate_lorenz_96(p=10, F=10, T=1000)\n",
    "X = torch.tensor(X_np[np.newaxis], dtype=torch.float64, device=device)\n",
    "X = X.reshape(10,1000)\n",
    "input_ = torch.arange(0,1000, 1, device = device, dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = torch.rand((10,1000), device = device, dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(model_pred, True_target):\n",
    "    Y = True_target\n",
    "    X = True_target - model_pred\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, R_X = make_dataset(model_pred, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_input(data, context):\n",
    "    '''\n",
    "    Arrange a single time series into overlapping short sequences.\n",
    "    Args:\n",
    "      data: time series of shape (T, dim).\n",
    "      context: length of short sequences.\n",
    "    '''\n",
    "    assert context >= 1 and isinstance(context, int)\n",
    "    input = torch.zeros(len(data) - context, context, data.shape[1],\n",
    "                        dtype=torch.float32, device=data.device)\n",
    "    target = torch.zeros(len(data) - context, context, data.shape[1],\n",
    "                         dtype=torch.float32, device=data.device)\n",
    "    for i in range(context):\n",
    "        start = i\n",
    "        end = len(data) - context + i\n",
    "        input[:, i, :] = data[start:end]\n",
    "        target[:, i, :] = data[start+1:end+1]\n",
    "    return input.detach(), target.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ori, target_ori = arrange_input(X.T, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = input.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.zeros(len(data) - 10, 10, data.shape[1],\n",
    "                    dtype=torch.float64, device=data.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([990, 10, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(model_pred, True_target, context):\n",
    "    \n",
    "    # input 은 해결\n",
    "    Y = True_target.T\n",
    "    Rx = True_target - model_pred\n",
    "\n",
    "    assert context >= 1 and isinstance(context, int)\n",
    "    input = torch.zeros(Y.size(-1), Y.size(0) - context, context, Y.size(-1) - 1,\n",
    "                        dtype=torch.float32, device = device)\n",
    "    target = torch.zeros(Y.size(0) - context, context, Y.size(-1),\n",
    "                         dtype=torch.float32, device = device)\n",
    "    R_input = torch.zeros_like(target)\n",
    "    \n",
    "    ##################################################################################\n",
    "    \n",
    "    for i in range(Y.size(-1)):\n",
    "        \n",
    "        if i == 0:\n",
    "            Rx_feature = Rx[1:].T\n",
    "        elif i == Y.size(0) - 1:\n",
    "            Rx_feature = Rx[:-1].T\n",
    "        else:\n",
    "            Rx_feature = torch.cat((Rx[:i], Rx[i+1:])).T\n",
    "\n",
    "        for j in range(context):\n",
    "            start = j\n",
    "            end = X.size(-1) - context + j\n",
    "            input[i, :, j, :] = Rx_feature[start:end] \n",
    "            target[:, j, :] = Y[start+1:end+1]\n",
    "            R_input[:, j, :] = model_pred.T[start:end]\n",
    "\n",
    "    return input.detach(), target.detach(), R_input.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, target, R_input = make_dataset(model_pred, X, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 990, 10, 9])\n",
      "torch.Size([990, 10, 10])\n",
      "torch.Size([990, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "print(input.size())\n",
    "print(target.size())\n",
    "print(R_input.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = input.T\n",
    "X = input - R_X\n",
    "X_feature = X[1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_series, hidden):\n",
    "        '''\n",
    "        LSTM model with output layer to generate predictions.\n",
    "        Args:\n",
    "          num_series: number of input time series.\n",
    "          hidden: number of hidden units.\n",
    "        '''\n",
    "        super(LSTM, self).__init__()\n",
    "        self.p = num_series\n",
    "        self.hidden = hidden\n",
    "\n",
    "        # Set up network.\n",
    "        self.lstm = nn.LSTM(num_series, hidden, batch_first=True)\n",
    "        self.lstm.flatten_parameters()\n",
    "        self.linear = nn.Conv1d(hidden, 1, 1)\n",
    "\n",
    "    def init_hidden(self, batch):\n",
    "        '''Initialize hidden states for LSTM cell.'''\n",
    "        device = self.lstm.weight_ih_l0.device\n",
    "        return (torch.zeros(1, batch, self.hidden, device=device),\n",
    "                torch.zeros(1, batch, self.hidden, device=device))\n",
    "\n",
    "    def forward(self, X, hidden=None):\n",
    "        # Set up hidden state.\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(X.shape[0])\n",
    "\n",
    "        # Apply LSTM.\n",
    "        X, hidden = self.lstm(X, hidden)\n",
    "\n",
    "        # Calculate predictions using output layer.\n",
    "        X = X.transpose(2, 1)\n",
    "        X = self.linear(X)\n",
    "        return X.transpose(2, 1), hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(9,10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, hid = lstm(input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([990, 10, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, target, R_input = make_dataset(model_pred, X, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([990, 10, 10])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([990, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_input[:,:,1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5520, 0.3458, 0.3096,  ..., 1.2245, 0.8038, 1.0267],\n",
       "        [0.3432, 0.3069, 0.4932,  ..., 0.8042, 1.0267, 0.3991],\n",
       "        [0.3379, 0.5191, 0.4669,  ..., 1.0270, 0.3993, 0.7455],\n",
       "        ...,\n",
       "        [0.0623, 0.9484, 0.8254,  ..., 0.5040, 0.0643, 0.5523],\n",
       "        [0.9573, 0.8179, 0.9048,  ..., 0.0642, 0.5523, 1.0576],\n",
       "        [0.8075, 0.9410, 0.0548,  ..., 0.5532, 1.0578, 0.4516]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:,:,0] + R_input[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBFGC(nn.Module):\n",
    "    def __init__(self, infeature, hidden, device):\n",
    "        super(RBFGC, self).__init__()\n",
    "\n",
    "        self.infeature = infeature\n",
    "        self.hidden = hidden\n",
    "        self.device = device\n",
    "        self.networks = nn.ModuleList([LSTM(infeature-1, hidden) for _ in range(self.infeature)])\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \n",
    "        if hidden is None:\n",
    "            hidden = [None for _ in range(self.infeature)]\n",
    "        pred = [self.networks[i](X[i], hidden[i]) for i in range(self.infeature)]\n",
    "        pred, hidden = zip(*pred)\n",
    "        pred = torch.cat(pred, dim=2)\n",
    "        return pred, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_ori = LSTM(10,10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np, GC = simulate_lorenz_96(p=10, F=10, T=1000)\n",
    "X2 = torch.tensor(X_np[np.newaxis], dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000, 10])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ori, target_ori = zip(*[arrange_input(x, 10) for x in X2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([990, 10, 10])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ori[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([990, 10, 10])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_ori[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ori = torch.cat(input_ori, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([990, 10, 10])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ori.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1000])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([990, 10, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_ori(input_ori)[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([990, 10, 10])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_ori.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(RBF_model_pred, True_target, context):\n",
    "    \n",
    "    # input 은 해결\n",
    "    Y = True_target.T\n",
    "    Rx = True_target - RBF_model_pred\n",
    "\n",
    "    assert context >= 1 and isinstance(context, int)\n",
    "    input = torch.zeros(Y.size(-1), Y.size(0) - context, context, Y.size(-1) - 1,\n",
    "                        dtype=torch.float32, device = device)\n",
    "    target = torch.zeros(Y.size(0) - context, context, Y.size(-1),\n",
    "                         dtype=torch.float32, device = device)\n",
    "    R_input = torch.zeros_like(target)\n",
    "    \n",
    "    ##################################################################################\n",
    "    \n",
    "    for i in range(Y.size(-1)):\n",
    "        \n",
    "        if i == 0:\n",
    "            Rx_feature = Rx[1:].T\n",
    "        elif i == Y.size(0) - 1:\n",
    "            Rx_feature = Rx[:-1].T\n",
    "        else:\n",
    "            Rx_feature = torch.cat((Rx[:i], Rx[i+1:])).T\n",
    "\n",
    "        for j in range(context):\n",
    "            start = j\n",
    "            end = X.size(-1) - context + j\n",
    "            input[i, :, j, :] = Rx_feature[start:end] \n",
    "            target[:, j, :] = Y[start+1:end+1]\n",
    "            R_input[:, j, :] = RBF_model_pred[start:end]\n",
    "\n",
    "    return input.detach(), target.detach(), R_input.detach()\n",
    "\n",
    "def train_model_adam(clstm, X, RBF_model_pred, context, lr, max_iter, lam=0, lam_ridge=0,\n",
    "                     lookback=5, check_every=50, verbose=1):\n",
    "    '''Train model with Adam.'''\n",
    "    p = X.shape[-1]\n",
    "    loss_fn = nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(clstm.parameters(), lr=lr)\n",
    "    train_loss_list = []\n",
    "\n",
    "    # Set up data.\n",
    "    X, Y, R_X = make_dataset(RBF_model_pred, X, context)\n",
    "    # X = torch.cat(X, dim=0)\n",
    "    # Y = torch.cat(Y, dim=0)\n",
    "\n",
    "    # For early stopping.\n",
    "    best_it = None\n",
    "    best_loss = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        # Calculate loss.\n",
    "        pred = [clstm.networks[i](X)[0] for i in range(p)]\n",
    "        loss = sum([loss_fn(pred[i][:, :, 0] + R_X[:,:,i], Y[:, :, i]) for i in range(p)])\n",
    "\n",
    "        # Add penalty term.\n",
    "        if lam > 0:\n",
    "            loss = loss + sum([regularize(net, lam) for net in clstm.networks])\n",
    "\n",
    "        if lam_ridge > 0:\n",
    "            loss = loss + sum([ridge_regularize(net, lam_ridge)\n",
    "                               for net in clstm.networks])\n",
    "\n",
    "        # Take gradient step.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        clstm.zero_grad()\n",
    "\n",
    "        # Check progress.\n",
    "        if (it + 1) % check_every == 0:\n",
    "            mean_loss = loss / p\n",
    "            train_loss_list.append(mean_loss.detach())\n",
    "\n",
    "            if verbose > 0:\n",
    "                print(('-' * 10 + 'Iter = %d' + '-' * 10) % (it + 1))\n",
    "                print('Loss = %f' % mean_loss)\n",
    "\n",
    "            # Check for early stopping.\n",
    "            if mean_loss < best_loss:\n",
    "                best_loss = mean_loss\n",
    "                best_it = it\n",
    "                best_model = deepcopy(clstm)\n",
    "            elif (it - best_it) == lookback * check_every:\n",
    "                if verbose:\n",
    "                    print('Stopping early')\n",
    "                break\n",
    "\n",
    "    # Restore best model.\n",
    "    restore_parameters(clstm, best_model)\n",
    "\n",
    "    return train_loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cooling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
