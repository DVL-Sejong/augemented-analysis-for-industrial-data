{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import style\n",
    "style.use('seaborn-whitegrid')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiRBFnn(nn.Module):\n",
    "    def __init__(self, in_feature, add_rbf_num, device):\n",
    "        super(MultiRBFnn, self).__init__()\n",
    "\n",
    "        self.add_rbf_num = add_rbf_num  # additional RBFs number\n",
    "        self.in_feature = in_feature    # count features\n",
    "        self.device = device\n",
    "        self.centers_list = []\n",
    "        self.sigmas_list = []\n",
    "        self.weights_list = []\n",
    "\n",
    "        self.change_th = 3\n",
    "\n",
    "    def first_rbf_parameter(self, input_data, target): # done\n",
    "\n",
    "        # input_data shape : (data_num)\n",
    "        # target data shape : (in_feature, data_num)\n",
    "        \n",
    "        # first layer centers, weights, sigmas\n",
    "        # centers, sigmas : (add_rbf_num, 1)\n",
    "        # weights : (in_feature, add_rbf_num)\n",
    "\n",
    "        find_index_input = input_data.clone().detach()\n",
    "        fine_index_target = target.clone().detach()\n",
    "\n",
    "        find_sigma = target.clone().detach()\n",
    "        find_weight = target.clone().detach()\n",
    "        center_index_list = []\n",
    "\n",
    "        # first MultiRBFs initial centers and weights parameters\n",
    "        for i in range(self.add_rbf_num):\n",
    "            index_ = torch.argmax(torch.sum(torch.abs(fine_index_target), dim = 0)).cpu().detach().tolist()\n",
    "            fine_index_target[:,index_] = 0\n",
    "            center_index_list.append(index_)\n",
    "\n",
    "        center_index_list = torch.tensor(center_index_list, device= self.device)\n",
    "        initcenter = torch.index_select(find_index_input, 0, center_index_list)[-self.add_rbf_num:].reshape(self.add_rbf_num,1)\n",
    "        initweight = torch.index_select(find_weight, 1, center_index_list)[-self.add_rbf_num:].reshape(self.in_feature, self.add_rbf_num)\n",
    "\n",
    "        # first MultiRBFs initial sigmas parameters                \n",
    "        sigma_list = []\n",
    "        dft = torch.log(torch.abs(torch.fft.fft(find_sigma).real))\n",
    "        dft =  torch.abs(dft / torch.max(dft)) **-1\n",
    "        for k in center_index_list:\n",
    "            sigma_list.append(torch.mean(dft[:,k]).reshape(1))\n",
    "\n",
    "        initsigma = torch.cat(sigma_list)[-self.add_rbf_num:].reshape(self.add_rbf_num, 1)\n",
    "\n",
    "        # print(initcenter, initweight, initsigma)\n",
    "        return initcenter, initweight, initsigma\n",
    "    \n",
    "    def add_rbf_parameter(self, input_data, error):\n",
    "        find_index_input = input_data.clone().detach()\n",
    "        find_index_error = error.clone().detach()\n",
    "        \n",
    "        find_weight = error.clone().detach()\n",
    "        find_sigma = error.clone().detach()\n",
    "        \n",
    "        center_index_list = []\n",
    "\n",
    "        for i in range(self.add_rbf_num * (self.change_time + 1)):\n",
    "            index_ = torch.argmax(torch.sum(torch.abs(find_index_error), dim = 0)).cpu().detach().tolist()\n",
    "\n",
    "            find_index_error[:,index_] = 0\n",
    "            center_index_list.append(index_)\n",
    "\n",
    "        center_index_list = torch.tensor(center_index_list, device=self.device)\n",
    "        initcenter = torch.index_select(find_index_input, 0, center_index_list)[-self.add_rbf_num:].reshape(self.add_rbf_num,1)\n",
    "        initweight = torch.index_select(find_weight, 1, center_index_list)[::,-self.add_rbf_num:].reshape(self.in_feature, self.add_rbf_num)\n",
    "\n",
    "\n",
    "        sigma_list = []\n",
    "        dft = torch.log(torch.abs(torch.fft.fft(find_sigma).real))\n",
    "        \n",
    "        dft = (torch.abs(dft / torch.max(dft))**-1)\n",
    "        for k in center_index_list:\n",
    "            sigma_list.append(torch.mean(dft[:,k]).reshape(1))\n",
    "        initsigma = torch.cat(sigma_list)[-self.add_rbf_num:].reshape(self.add_rbf_num,1)\n",
    "        #print(initcenter, initweight, initsigma)\n",
    "        return initcenter, initweight, initsigma\n",
    "    \n",
    "    \n",
    "    def rbf_gaussian(self, input_data):\n",
    "        out = torch.exp(-1 *(torch.pow((input_data - self.centers), 2)) / (torch.pow(self.sigma, 2)))\n",
    "\n",
    "        return out\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        R = self.rbf_gaussian(input_data)\n",
    "        pred = torch.mm(self.weights, R)\n",
    "\n",
    "        return R, pred\n",
    "\n",
    "    def rbf_gaussian_derivative_centers(self, input_data): # done\n",
    "        output = (2 * (input_data - self.centers) / (torch.pow(self.sigma, 2))) * self.rbf_gaussian(input_data)\n",
    "\n",
    "        return output  # size = (add_rbf_num, data_num)\n",
    "\n",
    "    def rbf_gaussian_derivative_sigma(self, input_data): # done\n",
    "        output = (2 * torch.pow((input_data - self.centers), 2) / (torch.pow(self.sigma, 3))) * self.rbf_gaussian(input_data)\n",
    "\n",
    "        return output  # size = (add_rbf_num, data_num)\n",
    "    \n",
    "    # FUNCTION GRADIENT\n",
    "    def rbf_gradient(self, input_data, centers, sigmas, weights):\n",
    "        rbf_output = (-2 * (input_data-centers) / torch.pow(sigmas,2)) * \\\n",
    "                        (torch.exp(-1 * (torch.pow((input_data - centers), 2) / (torch.pow(sigmas, 2)))))\n",
    "        rbf_grad = torch.mm(weights, rbf_output)\n",
    "        \n",
    "        return rbf_grad\n",
    "    \n",
    "    def first_grad(input_data, target):\n",
    "        space = (input_data,)\n",
    "        for i in range(target.size(0)):\n",
    "            if i == 0:\n",
    "                f_grad = torch.gradient(target[i], spacing = space, edge_order  = 1)[0]\n",
    "            else:\n",
    "                f_grad = torch.vstack([f_grad, torch.gradient(target[i], spacing = space, edge_order  = 1)[0]])\n",
    "        return f_grad\n",
    "    \n",
    "    def target_grad(self, input_data, centers, sigmas, weights, f_grad):\n",
    "        true_grad = f_grad - self.rbf_gradient(input_data, centers, sigmas, weights)\n",
    "        \n",
    "        return true_grad\n",
    "    \n",
    "    def rbf_gaussian_derivative_centers(self, input_data):\n",
    "        output = (2 * (input_data - self.centers) / \\\n",
    "                  (torch.pow(self.sigma, 2))) * self.rbf_gaussian(input_data)\n",
    "\n",
    "        return output  # size = (num_radial, 1)\n",
    "    \n",
    "    def rbf_gaussian_derivative_sigma(self, input_data):\n",
    "        output = (2 * torch.pow((input_data - self.centers), 2) / \\\n",
    "                (torch.pow(self.sigma, 3))) * self.rbf_gaussian(input_data)\n",
    "\n",
    "        return output  # size = (num_radial, 1)\n",
    "\n",
    "    def L2_F(self, input_data):\n",
    "        return -2 * (input_data - self.centers) / torch.pow(self.sigma, 2)\n",
    "    \n",
    "    def L2_2_derivateive_weight(self, input_data, radial_output):\n",
    "        return (-2 *(input_data - self.centers) / torch.pow(self.sigma,2)) * radial_output\n",
    "    \n",
    "    def masking(self, target):\n",
    "    \n",
    "        # value_masking vector\n",
    "        value_masking = torch.where(target.isnan(), 0.0, 1.0)\n",
    "\n",
    "        # gradient masking vector\n",
    "        dim1 = (target.isnan().nonzero(as_tuple=True)[0]).detach().cpu().to().tolist()\n",
    "        dim2_backward = (target.isnan().nonzero(as_tuple=True)[1] + 1).detach().cpu().to().tolist()\n",
    "        dim2_forward = (target.isnan().nonzero(as_tuple=True)[1] -1).detach().cpu().to().tolist()\n",
    "\n",
    "        grad_masking = torch.where(target.isnan(), 0.0, 1.0)\n",
    "        grad_masking[dim1, dim2_backward] = 0.0\n",
    "        grad_masking[dim1, dim2_forward] = 0.0\n",
    "        \n",
    "        return value_masking, grad_masking\n",
    "\n",
    "\n",
    "    # Backpropagation and train\n",
    "\n",
    "    def BP(self, input_data, target, R, pred, target_grad, pred_grad):\n",
    "        L2_1_error = -2 * (target - pred)\n",
    "\n",
    "        L2_2_error = -2 * (target_grad - pred_grad)\n",
    "\n",
    "        observation_len = torch.sum(self.value_missng)\n",
    "\n",
    "        # sigma update\n",
    "        deltaSigma1 = self.rbf_gaussian_derivative_sigma(input_data) * L2_1_error.reshape(self.in_feature, 1, input_data.size(0))\n",
    "        deltaSigma1 *= self.weights.reshape(self.in_feature, self.add_rbf_num, 1)\n",
    "\n",
    "        deltaSigma2 = self.rbf_gaussian_derivative_sigma(input_data) * L2_2_error.reshape(self.in_feature, 1, input_data.size(0))\n",
    "        deltaSigma2 *= self.L2_F(input_data) * self.weights.reshape(self.in_feature, self.add_rbf_num, 1)\n",
    "\n",
    "        # deltaSigma =  torch.mean(torch.sum(deltaSigma1, dim=2), dim = 0) + torch.mean(torch.sum(deltaSigma2, dim=2), dim = 0)\n",
    "        deltaSigma = torch.sum(deltaSigma1, dim=2) / observation_len + torch.sum(deltaSigma2, dim=2) / observation_len\n",
    "\n",
    "        # center update\n",
    "        deltaCenter1 = self.rbf_gaussian_derivative_centers(input_data) * L2_1_error.reshape(self.in_feature, 1, input_data.size(0))\n",
    "        deltaCenter1 *= self.weights.reshape(self.in_feature, self.add_rbf_num, 1)\n",
    "\n",
    "        deltaCenter2 = self.rbf_gaussian_derivative_centers(input_data) * L2_2_error.reshape(self.in_feature, 1, input_data.size(0))\n",
    "        deltaCenter2 *= self.L2_F(input_data) * self.weights.reshape(self.in_feature, self.add_rbf_num, 1)\n",
    "        # deltaCenter =  torch.mean(torch.sum(deltaCenter1, dim=2), dim = 0) + torch.mean(torch.sum(deltaCenter2, dim=2), dim = 0)\n",
    "        deltaCenter =  torch.sum(deltaCenter1, dim=2) / observation_len + torch.sum(deltaCenter2, dim=2) / observation_len\n",
    "        \n",
    "        # weight update\n",
    "        delta_weight1 = torch.sum((R * L2_1_error.reshape(self.in_feature, 1, input_data.size(0))), dim=2)\n",
    "        delta_weight2 = torch.sum(self.L2_2_derivateive_weight(input_, R) * L2_2_error.reshape(self.in_feature, 1, input_data.size(0)), dim = 2)\n",
    "        delta_weight = delta_weight1 + delta_weight2\n",
    "        \n",
    "        # BP update\n",
    "        self.weights -= self.lr * delta_weight\n",
    "        #self.centers -= self.lr * torch.sum(deltaCenter1, dim=1).reshape(self.add_rbf_num, 1)\n",
    "        #self.sigma -= self.lr * torch.sum(deltaSigma1, dim=1).reshape(self.add_rbf_num, 1)\n",
    "        self.centers -= self.lr * deltaCenter.reshape(self.add_rbf_num, 1)\n",
    "        self.sigma -= self.lr * deltaSigma.reshape(self.add_rbf_num, 1)\n",
    "\n",
    "    def change_init(self, na):\n",
    "        if na == 1:\n",
    "            loss_list = self.train_loss_list[-self.change_th:]\n",
    "            if self.number > self.change_th and max(loss_list) == min(loss_list):\n",
    "                self.change_time += 1\n",
    "            elif self.number > self.change_th and loss_list[0] < loss_list[1] and loss_list[1] < loss_list[2]:\n",
    "                self.change_time += 1\n",
    "            else:\n",
    "                self.change_time = 0\n",
    "        else:\n",
    "            self.change_time += 1\n",
    "    \n",
    "    def plot_train(self, input_data, best_pred): #done\n",
    "        if self.in_feature != 1:\n",
    "            fig, ax = plt.subplots(1, self.in_feature, figsize = (30, 5))\n",
    "            for i in range(self.in_feature):\n",
    "                ax[i].plot(input_data.cpu().detach().numpy(), self.target[i].cpu().detach().numpy())\n",
    "                ax[i].plot(input_data.cpu().detach().numpy(), best_pred[i].cpu().detach().numpy())\n",
    "            plt.show()\n",
    "        \n",
    "        else:\n",
    "            plt.plot(input_data.cpu().detach().numpy(), self.target[0].cpu().detach().numpy())\n",
    "            plt.plot(input_data.cpu().detach().numpy(), best_pred[0].cpu().detach().numpy())\n",
    "            plt.show()\n",
    "\n",
    "    def best_forward(self, input_data, best_center, best_sigma, best_weight): # ?\n",
    "        rbf_output = torch.exp(-1 * (torch.pow((input_data - best_center), 2) / \\\n",
    "                                        (torch.pow(best_sigma, 2))))\n",
    "        pred = torch.mm(best_weight, rbf_output)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def Loss(self, pred, target, pred_grad, true_grad):\n",
    "        # value L2 loss  \n",
    "\n",
    "        return torch.sum(torch.pow(target - pred,2) + torch.pow(true_grad - pred_grad, 2)) / torch.sum(self.value_masking)\n",
    "    \n",
    "    def pred(self, input_data):\n",
    "        rbf_output = torch.exp(-1 * (torch.pow((input_data - self.done_centers), 2) / \\\n",
    "                                     (torch.pow(self.done_sigma, 2))))\n",
    "        pred = torch.mm(self.done_weights, rbf_output)\n",
    "\n",
    "        return rbf_output, pred\n",
    "        \n",
    "    def train(self, input_data, target, epochs, lr, loss_th, lr_change_th):\n",
    "        self.lr = lr\n",
    "        self.target = target.clone().detach()\n",
    "        self.number = 0\n",
    "        self.train_loss_list = []\n",
    "        self.loss_th = loss_th\n",
    "        self.lr_change_th = lr_change_th\n",
    "        self.target_mape_th = torch.mean(torch.abs(target)) * 0.05\n",
    "        self.round_number = 5\n",
    "        self.change_time = 0\n",
    "        count_loss_chage = 0\n",
    "        count_round_change = 0\n",
    "\n",
    "        break_time = len(input_data) / self.add_rbf_num\n",
    "\n",
    "        loss = 100000\n",
    "        \n",
    "        while self.loss_th < loss:\n",
    "\n",
    "            print(\"{}th additional rbflayer\".format(self.number))\n",
    "            # first rbflayer\n",
    "            if self.number == 0:\n",
    "                self.value_masking, self.grad_masking = self.masking(self.target)\n",
    "                self.centers, self.weights, self.sigma = self.first_rbf_parameter(input_data, self.target)\n",
    "                first_grad = torch.nan_to_num(self.first_grad(input_data, target))\n",
    "\n",
    "                for epoch in range(epochs):\n",
    "                    # print(\"epoch : {}\".format(epoch))\n",
    "                    R, pred = self.forward(input_data)\n",
    "                    rbf_grad = self.rbf_gradient(input_data, self.centers, self.sigma, self.weights) * self.value_masking\n",
    "\n",
    "                    self.BP(input_data, self.target, R, pred, first_grad, rbf_grad)\n",
    "                    R, pred = self.forward(input_data)\n",
    "                    rbf_grad = self.rbf_gradient(input_data, self.centers, self.sigma, self.weights) * self.value_masking\n",
    "                    epoch_loss = self.Loss(pred, self.target, rbf_grad, first_grad)\n",
    "\n",
    "                    if epoch == 0:\n",
    "                        print(\"{}th additional RBFlayer {}th epoch loss: {}\".format(self.number, epoch, epoch_loss))\n",
    "                        self.best_loss = epoch_loss.clone().detach()\n",
    "                        self.best_center = self.centers.clone().detach()\n",
    "                        self.best_sigma = self.sigma.clone().detach()\n",
    "                        self.best_weight = self.weights.clone().detach()\n",
    "                    \n",
    "                    else:\n",
    "                        if self.best_loss > epoch_loss:\n",
    "                            self.best_loss = epoch_loss.clone().detach()\n",
    "                            self.best_center = self.centers.clone().detach()\n",
    "                            self.best_sigma = self.sigma.clone().detach()\n",
    "                            self.best_weight = self.weights.clone().detach()\n",
    "\n",
    "                    if (epoch + 1) % 1000 == 0:\n",
    "                        print(\"{}th additional RBFlayer {}th epoch MSE Loss: {}\".format(self.number, epoch, epoch_loss))\n",
    "\n",
    "            else:\n",
    "                self.change_init(na)\n",
    "                if self.change_time > break_time:\n",
    "                    break\n",
    "                \n",
    "                \n",
    "                self.centers, self.weights, self.sigma = self.add_rbf_parameter(input_data, self.target)\n",
    "\n",
    "                for epoch in range(epochs):\n",
    "                    # print('epoch : {}'.format(epoch))\n",
    "                    R, pred = self.forward(input_data)\n",
    "                    rbf_grad = self.rbf_gradient(input_data, self.centers, self.sigma, self.weights) * self.value_masking\n",
    "                    if epoch == 0:\n",
    "                        \n",
    "                        print(\"{}th additional RBFlayer {}th epoch loss: {}\".format(self.number, epoch,\n",
    "                                                                                        self.Loss(pred, self.target, rbf_grad, torch.nan_to_num(target_grad))))\n",
    "                        self.best_loss = self.Loss(pred, self.target, rbf_grad, torch.nan_to_num((target_grad).clone().detach()))\n",
    "                        self.best_center = self.centers.clone().detach()\n",
    "                        self.best_sigma = self.sigma.clone().detach()\n",
    "                        self.best_weight = self.weights.clone().detach()\n",
    "\n",
    "                    self.BP(input_data, self.target, R, pred, torch.nan_to_num(target_grad), rbf_grad)\n",
    "                    # R, pred = self.forward(input_data)\n",
    "                    # rbf_grad = self.rbf_gradient(input_data, self.centers, self.sigma, self.weights)\n",
    "                    epoch_loss = self.Loss(pred, self.target, rbf_grad, torch.nan_to_num(target_grad))\n",
    "\n",
    "                    if (epoch + 1) % 1000 == 0:\n",
    "                        print(\"{}th additional RBFlayer {}th epoch MSE Loss: {}\".format(self.number, epoch, epoch_loss))\n",
    "                    \n",
    "                    if self.best_loss > epoch_loss:\n",
    "                        self.best_loss = epoch_loss.clone().detach()\n",
    "                        self.best_center = self.centers.clone().detach()\n",
    "                        self.best_sigma = self.sigma.clone().detach()\n",
    "                        self.best_weight = self.weights.clone().detach()\n",
    "                \n",
    "            best_pred = self.best_forward(input_data, self.best_center, self.best_sigma, self.best_weight)\n",
    "            best_grad = self.rbf_gradient(input_data, self.best_center, self.best_sigma, self.best_weight)\n",
    "            if self.number ==0:\n",
    "                train_loss = self.Loss(best_pred, self.target, best_grad, first_grad)\n",
    "            else:\n",
    "                train_loss = self.Loss(best_pred, self.target, best_grad, target_grad)\n",
    "\n",
    "            print(\"{}th additional RBFlayer best loss : {}\".format(self.number, train_loss))\n",
    "\n",
    "            if self.best_loss < self.lr_change_th:\n",
    "                count_loss_chage += 1\n",
    "                self.lr *= 10\n",
    "                self.lr_change_th *= 0.03\n",
    "                print(\"change lr \", self.lr)\n",
    "                print('----------------------------------------------')\n",
    "                \n",
    "            if count_round_change == 0 and train_loss < self.target_mape_th:\n",
    "                count_round_change += 1\n",
    "                self.round_number += 1\n",
    "                print(\"change round number\", self.round_number)\n",
    "                print('----------------------------------------------')\n",
    "                \n",
    "            self.train_loss_list.append(train_loss)\n",
    "\n",
    "            # additional rbf plot print\n",
    "            self.plot_train(input_data, best_pred)\n",
    "\n",
    "            if torch.isnan(train_loss) == False:\n",
    "                na = 1\n",
    "                self.target = self.target - best_pred  # target update\n",
    "                loss = train_loss  # loss update\n",
    "                self.number += 1  # additional rbf number update\n",
    "                self.centers_list.append(self.best_center)\n",
    "                self.sigmas_list.append(self.best_sigma)\n",
    "                self.weights_list.append(self.best_weight)\n",
    "\n",
    "                self.done_centers = torch.cat(self.centers_list, dim  =0)\n",
    "                self.done_sigma = torch.cat(self.sigmas_list, dim = 0)\n",
    "                self.done_weights = torch.cat(self.weights_list, dim = 1)\n",
    "                target_grad = self.target_grad(input_data, self.done_centers, self.done_sigma, self.done_weights, first_grad)\n",
    "\n",
    "            else:\n",
    "                na = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(input_data, centers, sigma, weights):\n",
    "    out = torch.exp(-1 *(torch.pow((input_data - centers), 2)) / (torch.pow(sigma, 2)))\n",
    "    pred = torch.mm(weights, out)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_c = torch.tensor([1.32141, 6.1256142, 4.21512, 3.16512, 7.1626, 8.735, 12.1624], dtype = float ,device= device).reshape(7,1)\n",
    "r_s = torch.tensor([1.1, 0.6142, 2.21512, 1.162, 0.626, 2.735, 1.1624], dtype = float ,device= device).reshape(7,1)\n",
    "r_w = torch.tensor([[-10, 12, 32, -33, 12, -20, 3],\n",
    "                    [12, -1, -22, 3, 32, -20, 4],\n",
    "                    [-10, 3, 23, -13, 23, 17, 2]], dtype = float, device = device)\n",
    "\n",
    "input_ = np.arange(1,15,0.5)\n",
    "input_ = torch.tensor(input_, device = device)\n",
    "target = gaussian(input_, r_c, r_s, r_w)\n",
    "target2 = gaussian(input_, r_c, r_s, r_w)\n",
    "\n",
    "target[0][2] = torch.nan\n",
    "target[0][6] = torch.nan\n",
    "target[0][9] = torch.nan\n",
    "target[0][15] = torch.nan\n",
    "target[0][16] = torch.nan\n",
    "\n",
    "target[1][3] = torch.nan\n",
    "target[1][5] = torch.nan\n",
    "target[1][1] = torch.nan\n",
    "target[1][19] = torch.nan\n",
    "target[1][26] = torch.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_grad(input_data, target):\n",
    "        space = (input_data,)\n",
    "        for i in range(target.size(0)):\n",
    "            if i == 0:\n",
    "                f_grad = torch.gradient(target[i], spacing = space, edge_order  = 1)[0]\n",
    "            else:\n",
    "                f_grad = torch.vstack([f_grad, torch.gradient(target[i], spacing = space, edge_order  = 1)[0]])\n",
    "        return f_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_grad = first_grad(input_, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0956e+00,         nan,         nan,         nan,  7.2457e+00,\n",
       "                 nan,         nan,         nan,         nan,         nan,\n",
       "                 nan, -1.5153e+01, -1.6674e+01, -2.0885e+01,         nan,\n",
       "                 nan,         nan,         nan,  5.5819e+00,  7.0520e+00,\n",
       "          7.7610e+00,  7.0996e+00,  4.7793e+00,  1.8948e+00,  8.5873e-02,\n",
       "         -2.7246e-01, -1.9558e-02,  1.2505e-01],\n",
       "        [        nan,         nan,         nan,         nan,         nan,\n",
       "                 nan,         nan, -1.3192e+00,  1.7292e+00,  3.5034e+00,\n",
       "          1.2825e+01,  3.0663e+01,  1.3275e+01, -2.6326e+01, -2.5216e+01,\n",
       "         -5.5639e+00,  1.4930e+00,  3.9654e+00,         nan,         nan,\n",
       "                 nan,  7.7167e+00,  4.9768e+00,  1.5093e+00, -5.6717e-01,\n",
       "                 nan,         nan,         nan],\n",
       "        [ 1.0192e+00,  3.6913e+00,  6.4545e+00,  6.6090e+00,  8.8155e+00,\n",
       "          1.2330e+01,  1.1697e+01,  6.1017e+00,  7.8346e-01, -1.0606e-01,\n",
       "          4.7440e+00,  1.6153e+01,  7.4141e+00, -1.7098e+01, -1.5977e+01,\n",
       "         -3.8362e+00, -1.8512e+00, -3.2491e+00, -4.3334e+00, -4.5138e+00,\n",
       "         -3.9120e+00, -3.2505e+00, -3.1698e+00, -3.3657e+00, -3.0446e+00,\n",
       "         -2.1017e+00, -1.1141e+00, -6.9443e-01]], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0956e+00, -8.6308e-01, -2.6247e+00, -2.6924e+00,  7.2457e+00,\n",
       "          2.0858e+01,  2.3095e+01,  1.1836e+01,  7.5424e-01, -1.6531e+00,\n",
       "         -8.6341e+00, -1.5153e+01, -1.6674e+01, -2.0885e+01, -1.5262e+01,\n",
       "         -4.6339e+00,  5.9779e-01,  3.4890e+00,  5.5819e+00,  7.0520e+00,\n",
       "          7.7610e+00,  7.0996e+00,  4.7793e+00,  1.8948e+00,  8.5873e-02,\n",
       "         -2.7246e-01, -1.9558e-02,  1.2505e-01],\n",
       "        [-2.5422e+00, -7.2688e+00, -1.3379e+01, -1.3580e+01, -1.1116e+01,\n",
       "         -8.5495e+00, -5.3172e+00, -1.3192e+00,  1.7292e+00,  3.5034e+00,\n",
       "          1.2825e+01,  3.0663e+01,  1.3275e+01, -2.6326e+01, -2.5216e+01,\n",
       "         -5.5639e+00,  1.4930e+00,  3.9654e+00,  5.8708e+00,  7.4428e+00,\n",
       "          8.3705e+00,  7.7167e+00,  4.9768e+00,  1.5093e+00, -5.6717e-01,\n",
       "         -7.8528e-01, -2.6806e-01, -4.2164e-03],\n",
       "        [ 1.0192e+00,  3.6913e+00,  6.4545e+00,  6.6090e+00,  8.8155e+00,\n",
       "          1.2330e+01,  1.1697e+01,  6.1017e+00,  7.8346e-01, -1.0606e-01,\n",
       "          4.7440e+00,  1.6153e+01,  7.4141e+00, -1.7098e+01, -1.5977e+01,\n",
       "         -3.8362e+00, -1.8512e+00, -3.2491e+00, -4.3334e+00, -4.5138e+00,\n",
       "         -3.9120e+00, -3.2505e+00, -3.1698e+00, -3.3657e+00, -3.0446e+00,\n",
       "         -2.1017e+00, -1.1141e+00, -6.9443e-01]], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_grad2 = first_grad(input_, target2)\n",
    "f_grad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jcy/cooling/BRITS/MissingRBF/gradient.ipynb Cell 5\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://tunnel%2Blocalhostlocaldomain/home/jcy/cooling/BRITS/MissingRBF/gradient.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m target[target \u001b[39m!=\u001b[39;49m target\u001b[39m.\u001b[39;49misnan(), target \u001b[39m!=\u001b[39;49m target\u001b[39m.\u001b[39;49misnan()]\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "target[target != target.isnan(), target != target.isnan()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.3209e+00, -6.8688e+00, -9.4935e+00, -9.8764e+00, -2.2478e+00,\n",
       "         2.0847e+01,  2.2817e+01,  2.1164e+01,  1.2967e+01,  6.0111e+00,\n",
       "        -3.7070e+00, -1.4874e+01, -1.8371e+01, -1.6019e+01, -1.2789e+01,\n",
       "        -8.9670e+00, -5.0283e+00, -1.8674e+00, -2.4894e-01,  2.7321e-02,\n",
       "        -1.6306e-01, -2.4514e-01, -1.8262e-01,  8.4284e+00,  1.1596e+00,\n",
       "        -1.2420e+01, -2.0970e+01, -2.2654e+01, -2.2289e+01, -2.0925e+01,\n",
       "        -1.8786e+01, -8.1002e+00,  1.1878e+01,  5.1751e+00, -1.4448e+01,\n",
       "        -2.0041e+01, -2.0012e+01, -1.8548e+01, -1.6047e+01, -8.6037e+00,\n",
       "        -4.3066e+00, -8.8700e-01,  6.7013e-01,  6.2229e-01,  1.0296e-01,\n",
       "        -1.6510e-01, -6.7820e+00, -6.2724e+00, -3.0908e+00,  1.8207e-01,\n",
       "         3.5182e+00,  8.9976e+00,  1.5848e+01,  2.0695e+01,  2.1950e+01,\n",
       "         2.1478e+01,  2.1844e+01,  2.6222e+01,  3.7997e+01,  3.3637e+01,\n",
       "         2.0899e+01,  1.7660e+01,  1.7063e+01,  1.5809e+01,  1.3814e+01,\n",
       "         1.1475e+01,  9.3000e+00,  7.5634e+00,  6.0496e+00,  4.3936e+00,\n",
       "         2.6839e+00,  1.3490e+00,  5.8218e-01,  2.3496e-01], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[target.isnan() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking(target):\n",
    "    \n",
    "    # value_masking vector\n",
    "    value_masking = torch.where(target.isnan(), 0.0, 1.0)\n",
    "\n",
    "    # gradient masking vector\n",
    "    dim1 = (target.isnan().nonzero(as_tuple=True)[0]).detach().cpu().to().tolist()\n",
    "    dim2_backward = (target.isnan().nonzero(as_tuple=True)[1] + 1).detach().cpu().to().tolist()\n",
    "    dim2_forward = (target.isnan().nonzero(as_tuple=True)[1] -1).detach().cpu().to().tolist()\n",
    "\n",
    "    grad_masking = torch.where(target.isnan(), 0.0, 1.0)\n",
    "    grad_masking[dim1, dim2_backward] = 0.0\n",
    "    grad_masking[dim1, dim2_forward] = 0.0\n",
    "    \n",
    "    return value_masking, grad_masking\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[23.],\n",
       "        [23.],\n",
       "        [28.]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(Vm, dim = 1).reshape(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vm,Gm = masking(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0956e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.2457e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -1.5153e+01, -1.6674e+01, -2.0885e+01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  5.5819e+00,  7.0520e+00,\n",
       "          7.7610e+00,  7.0996e+00,  4.7793e+00,  1.8948e+00,  8.5873e-02,\n",
       "         -2.7246e-01, -1.9558e-02,  1.2505e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -1.3192e+00,  1.7292e+00,  3.5034e+00,\n",
       "          1.2825e+01,  3.0663e+01,  1.3275e+01, -2.6326e+01, -2.5216e+01,\n",
       "         -5.5639e+00,  1.4930e+00,  3.9654e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  7.7167e+00,  4.9768e+00,  1.5093e+00, -5.6717e-01,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.0192e+00,  3.6913e+00,  6.4545e+00,  6.6090e+00,  8.8155e+00,\n",
       "          1.2330e+01,  1.1697e+01,  6.1017e+00,  7.8346e-01, -1.0606e-01,\n",
       "          4.7440e+00,  1.6153e+01,  7.4141e+00, -1.7098e+01, -1.5977e+01,\n",
       "         -3.8362e+00, -1.8512e+00, -3.2491e+00, -4.3334e+00, -4.5138e+00,\n",
       "         -3.9120e+00, -3.2505e+00, -3.1698e+00, -3.3657e+00, -3.0446e+00,\n",
       "         -2.1017e+00, -1.1141e+00, -6.9443e-01]], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nan_to_num(Vm * f_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_grad(input_data, target):\n",
    "    space = (input_data,)\n",
    "    f_grad = torch.gradient(target, spacing = space, edge_order  = 1)\n",
    "    return f_grad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.3209e+00, -6.8688e+00,         nan, -9.4935e+00, -9.8764e+00,\n",
       "         -2.2478e+00,         nan,  2.0847e+01,  2.2817e+01,         nan,\n",
       "          2.1164e+01,  1.2967e+01,  6.0111e+00, -3.7070e+00, -1.4874e+01,\n",
       "                 nan,         nan, -1.8371e+01, -1.6019e+01, -1.2789e+01,\n",
       "         -8.9670e+00, -5.0283e+00, -1.8674e+00, -2.4894e-01,  2.7321e-02,\n",
       "         -1.6306e-01, -2.4514e-01, -1.8262e-01],\n",
       "        [ 8.4284e+00,         nan,  1.1596e+00,         nan, -1.2420e+01,\n",
       "                 nan, -2.0970e+01, -2.2654e+01, -2.2289e+01, -2.0925e+01,\n",
       "         -1.8786e+01, -8.1002e+00,  1.1878e+01,  5.1751e+00, -1.4448e+01,\n",
       "         -2.0041e+01, -2.0012e+01, -1.8548e+01, -1.6047e+01,         nan,\n",
       "         -8.6037e+00, -4.3066e+00, -8.8700e-01,  6.7013e-01,  6.2229e-01,\n",
       "          1.0296e-01,         nan, -1.6510e-01],\n",
       "        [-6.7820e+00, -6.2724e+00, -3.0908e+00,  1.8207e-01,  3.5182e+00,\n",
       "          8.9976e+00,  1.5848e+01,  2.0695e+01,  2.1950e+01,  2.1478e+01,\n",
       "          2.1844e+01,  2.6222e+01,  3.7997e+01,  3.3637e+01,  2.0899e+01,\n",
       "          1.7660e+01,  1.7063e+01,  1.5809e+01,  1.3814e+01,  1.1475e+01,\n",
       "          9.3000e+00,  7.5634e+00,  6.0496e+00,  4.3936e+00,  2.6839e+00,\n",
       "          1.3490e+00,  5.8218e-01,  2.3496e-01]], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vm, Gm = masking(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_gradient(input_data, centers, sigmas, weights):\n",
    "    rbf_output = (-2 * (input_data-centers) / torch.pow(sigmas,2)) * \\\n",
    "                    (torch.exp(-1 * (torch.pow((input_data - centers), 2) / (torch.pow(sigmas, 2)))))\n",
    "    rbf_grad = torch.mm(weights, rbf_output)\n",
    "    \n",
    "    return rbf_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_Grad = rbf_gradient(input_, r_c, r_s, r_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.0780e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,  6.1463e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -1.9561e+01, -1.1700e+01, -2.6177e+01, -0.0000e+00,\n",
       "         -0.0000e+00,  0.0000e+00,  0.0000e+00,  5.6809e+00,  7.1520e+00,\n",
       "          7.9918e+00,  7.4446e+00,  4.9054e+00,  1.6483e+00, -2.0872e-01,\n",
       "         -3.5560e-01,  2.1655e-02,  1.8062e-01],\n",
       "        [ 0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -1.1543e+00,  2.2340e+00,  2.8364e+00,\n",
       "          8.3427e+00,  3.7602e+01,  2.4370e+01, -4.3282e+01, -2.4671e+01,\n",
       "         -2.6106e+00,  1.7646e+00,  4.0255e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  8.1564e+00,  5.1419e+00,  1.1892e+00, -9.4635e-01,\n",
       "         -0.0000e+00, -0.0000e+00,  0.0000e+00],\n",
       "        [-2.4946e+00,  4.4576e+00,  7.1676e+00,  5.9368e+00,  8.3396e+00,\n",
       "          1.3298e+01,  1.2784e+01,  6.0279e+00, -3.1569e-01, -4.8709e-01,\n",
       "          2.2256e+00,  1.9097e+01,  1.5909e+01, -2.8604e+01, -1.5230e+01,\n",
       "         -1.5270e+00, -1.6487e+00, -3.3413e+00, -4.5006e+00, -4.6721e+00,\n",
       "         -3.9248e+00, -3.1067e+00, -3.0977e+00, -3.4910e+00, -3.1790e+00,\n",
       "         -2.0943e+00, -1.0352e+00, -4.2942e-01]], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_Grad * Gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-3., -2.,  0.,  2.,  4.,  6.]),)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates = (torch.tensor([-2., -1.,0, 1.,2, 4.]),)\n",
    "values = torch.tensor([4., 1., 0, 1.,4., 16.], )\n",
    "torch.gradient(values, spacing = coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-3.0000, -2.0000,  4.0000,  6.0000]),)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates = (torch.tensor([-2., -1., 2., 4.]),)\n",
    "values = torch.tensor([4., 1., 4., 16.], )\n",
    "torch.gradient(values, spacing = coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.3209e+00, -6.8688e+00,         nan, -9.4935e+00, -9.8764e+00,\n",
       "         -2.2478e+00,         nan,  2.0847e+01,  2.2817e+01,         nan,\n",
       "          2.1164e+01,  1.2967e+01,  6.0111e+00, -3.7070e+00, -1.4874e+01,\n",
       "                 nan,         nan, -1.8371e+01, -1.6019e+01, -1.2789e+01,\n",
       "         -8.9670e+00, -5.0283e+00, -1.8674e+00, -2.4894e-01,  2.7321e-02,\n",
       "         -1.6306e-01, -2.4514e-01, -1.8262e-01],\n",
       "        [ 8.4284e+00,         nan,  1.1596e+00,         nan, -1.2420e+01,\n",
       "                 nan, -2.0970e+01, -2.2654e+01, -2.2289e+01, -2.0925e+01,\n",
       "         -1.8786e+01, -8.1002e+00,  1.1878e+01,  5.1751e+00, -1.4448e+01,\n",
       "         -2.0041e+01, -2.0012e+01, -1.8548e+01, -1.6047e+01,         nan,\n",
       "         -8.6037e+00, -4.3066e+00, -8.8700e-01,  6.7013e-01,  6.2229e-01,\n",
       "          1.0296e-01,         nan, -1.6510e-01],\n",
       "        [-6.7820e+00, -6.2724e+00, -3.0908e+00,  1.8207e-01,  3.5182e+00,\n",
       "          8.9976e+00,  1.5848e+01,  2.0695e+01,  2.1950e+01,  2.1478e+01,\n",
       "          2.1844e+01,  2.6222e+01,  3.7997e+01,  3.3637e+01,  2.0899e+01,\n",
       "          1.7660e+01,  1.7063e+01,  1.5809e+01,  1.3814e+01,  1.1475e+01,\n",
       "          9.3000e+00,  7.5634e+00,  6.0496e+00,  4.3936e+00,  2.6839e+00,\n",
       "          1.3490e+00,  5.8218e-01,  2.3496e-01]], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_gaussian_derivative_centers(self, input_data):\n",
    "    output = (2 * (input_data - self.centers) / \\\n",
    "                (torch.pow(self.sigma, 2))) * self.rbf_gaussian(input_data)\n",
    "\n",
    "    return output  # size = (num_radial, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dc = torch.tensor([[1],[3],[4],[5]], device = device, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor([[-10,4, 12,5],\n",
    "                        [12,3, -1,5],\n",
    "                        [-10,5, 3,5]], dtype = float, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaCenter2 = Dc * torch.nan_to_num(target).reshape(3, 1, input_.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.sum(deltaCenter2 * weights.reshape(3, 4, 1), dim = 2).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaCenter2 = rbf_gaussian_derivative_centers(input_) * torch.nan_to_num(target).reshape(3, 1, input_.size(0))\n",
    "deltaCenter2 *= L2_F(input_) * weights.reshape(3, add_rbf_num, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_rbf_parameter( input_data, target): # done\n",
    "\n",
    "    # input_data shape : (data_num)\n",
    "    # target data shape : (3, data_num)\n",
    "    \n",
    "    # first layer centers, weights, sigmas\n",
    "    # centers, sigmas : (4, 1)\n",
    "    # weights : (3, 4)\n",
    "\n",
    "    find_index_input = input_data.clone().detach()\n",
    "    fine_index_target = target.clone().detach()\n",
    "\n",
    "    find_sigma = target.clone().detach()\n",
    "    find_weight = target.clone().detach()\n",
    "    center_index_list = []\n",
    "\n",
    "    # first MultiRBFs initial centers and weights parameters\n",
    "    for i in range(4):\n",
    "        index_ = torch.argmax(torch.sum(torch.abs(fine_index_target), dim = 0)).cpu().detach().tolist()\n",
    "        fine_index_target[:,index_] = 0\n",
    "        center_index_list.append(index_)\n",
    "\n",
    "    center_index_list = torch.tensor(center_index_list, device= device)\n",
    "    initcenter = torch.index_select(find_index_input, 0, center_index_list)[-4:].reshape(4,1)\n",
    "    initweight = torch.index_select(find_weight, 1, center_index_list)[-4:].reshape(3, 4)\n",
    "\n",
    "    # first MultiRBFs initial sigmas parameters                \n",
    "    sigma_list = []\n",
    "    dft = torch.log(torch.abs(torch.fft.fft(find_sigma).real))\n",
    "    dft =  torch.abs(dft / torch.max(dft)) **-1\n",
    "    for k in center_index_list:\n",
    "        sigma_list.append(torch.mean(dft[:,k]).reshape(1))\n",
    "\n",
    "    initsigma = torch.cat(sigma_list)[-4:].reshape(4, 1)\n",
    "\n",
    "    # print(initcenter, initweight, initsigma)\n",
    "    return initcenter, initweight, initsigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5.0000],\n",
       "         [4.5000],\n",
       "         [6.0000],\n",
       "         [7.0000]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[ 22.8171,  20.8468,  21.1640,   6.0111],\n",
       "         [-22.2889, -22.6541, -18.7855,  11.8778],\n",
       "         [ 21.9499,  20.6950,  21.8439,  37.9970]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[2.0927],\n",
       "         [2.1295],\n",
       "         [2.1708],\n",
       "         [3.0031]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_rbf_parameter(input_, torch.nan_to_num(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5.0000],\n",
       "         [4.5000],\n",
       "         [5.5000],\n",
       "         [6.0000]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[ 22.8171,  20.8468,  21.6011,  21.1640],\n",
       "         [-22.2889, -22.6541, -20.9249, -18.7855],\n",
       "         [ 21.9499,  20.6950,  21.4785,  21.8439]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[3.1214],\n",
       "         [2.3658],\n",
       "         [5.0884],\n",
       "         [3.1916]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_rbf_parameter(input_, torch.nan_to_num(target2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cooling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
