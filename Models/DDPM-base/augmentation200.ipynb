{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864769a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abad8db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('C:/Users/chanyoung/Desktop/RBFfitting/data/linear_SEM/linear_random_15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92d5e61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col0</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>col11</th>\n",
       "      <th>col12</th>\n",
       "      <th>col13</th>\n",
       "      <th>col14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col0  col1  col2  col3  col4  col5  col6  col7  col8  col9  col10  col11  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0      0      0   \n",
       "\n",
       "   col12  col13  col14  \n",
       "0      0      0      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a377f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col0</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>col11</th>\n",
       "      <th>col12</th>\n",
       "      <th>col13</th>\n",
       "      <th>col14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col0  col1  col2  col3  col4  col5  col6  col7  col8  col9  col10  col11  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0   \n",
       "\n",
       "   col12  col13  col14  \n",
       "0    0.0    0.0    0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e12b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_row = pd.DataFrame(np.zeros((1, 15)), columns=data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64bccfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.394290</td>\n",
       "      <td>0.346584</td>\n",
       "      <td>2.283581</td>\n",
       "      <td>-1.559172</td>\n",
       "      <td>0.641352</td>\n",
       "      <td>-2.573262</td>\n",
       "      <td>-0.407517</td>\n",
       "      <td>2.417698</td>\n",
       "      <td>-1.459789</td>\n",
       "      <td>3.592460</td>\n",
       "      <td>-4.019680</td>\n",
       "      <td>0.790601</td>\n",
       "      <td>-1.833108</td>\n",
       "      <td>3.480442</td>\n",
       "      <td>6.263829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.442065</td>\n",
       "      <td>1.753741</td>\n",
       "      <td>-0.565542</td>\n",
       "      <td>-0.019844</td>\n",
       "      <td>-0.217345</td>\n",
       "      <td>-0.505208</td>\n",
       "      <td>-0.836395</td>\n",
       "      <td>3.096807</td>\n",
       "      <td>0.408895</td>\n",
       "      <td>-0.085744</td>\n",
       "      <td>-0.584852</td>\n",
       "      <td>-2.247291</td>\n",
       "      <td>0.499501</td>\n",
       "      <td>-1.568848</td>\n",
       "      <td>-1.472852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.158795</td>\n",
       "      <td>-2.018488</td>\n",
       "      <td>1.363381</td>\n",
       "      <td>0.369942</td>\n",
       "      <td>-0.553480</td>\n",
       "      <td>-0.829095</td>\n",
       "      <td>0.797979</td>\n",
       "      <td>-0.601401</td>\n",
       "      <td>3.293327</td>\n",
       "      <td>-1.130796</td>\n",
       "      <td>2.697072</td>\n",
       "      <td>-1.542107</td>\n",
       "      <td>5.722812</td>\n",
       "      <td>-1.352311</td>\n",
       "      <td>-10.048166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.180820</td>\n",
       "      <td>-0.302838</td>\n",
       "      <td>2.811929</td>\n",
       "      <td>-1.769756</td>\n",
       "      <td>1.171722</td>\n",
       "      <td>-4.010535</td>\n",
       "      <td>-0.339541</td>\n",
       "      <td>0.686395</td>\n",
       "      <td>-2.497994</td>\n",
       "      <td>-1.055499</td>\n",
       "      <td>-0.307648</td>\n",
       "      <td>-3.129533</td>\n",
       "      <td>2.950652</td>\n",
       "      <td>1.869410</td>\n",
       "      <td>1.805169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.535161</td>\n",
       "      <td>-1.304216</td>\n",
       "      <td>0.194147</td>\n",
       "      <td>-0.127602</td>\n",
       "      <td>-0.704615</td>\n",
       "      <td>1.089379</td>\n",
       "      <td>-0.192465</td>\n",
       "      <td>-2.312792</td>\n",
       "      <td>1.273764</td>\n",
       "      <td>1.341614</td>\n",
       "      <td>0.833310</td>\n",
       "      <td>0.889260</td>\n",
       "      <td>0.310092</td>\n",
       "      <td>-0.762782</td>\n",
       "      <td>-5.504899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.840972</td>\n",
       "      <td>0.419546</td>\n",
       "      <td>-0.149228</td>\n",
       "      <td>-2.066541</td>\n",
       "      <td>-1.074929</td>\n",
       "      <td>-2.850332</td>\n",
       "      <td>0.213039</td>\n",
       "      <td>-0.793650</td>\n",
       "      <td>1.961616</td>\n",
       "      <td>-0.598479</td>\n",
       "      <td>2.261300</td>\n",
       "      <td>-1.971938</td>\n",
       "      <td>4.682809</td>\n",
       "      <td>-3.231114</td>\n",
       "      <td>-8.642133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.944198</td>\n",
       "      <td>-0.182270</td>\n",
       "      <td>2.034609</td>\n",
       "      <td>-1.864585</td>\n",
       "      <td>2.520702</td>\n",
       "      <td>-3.416261</td>\n",
       "      <td>-1.658307</td>\n",
       "      <td>2.704336</td>\n",
       "      <td>-2.603829</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.012510</td>\n",
       "      <td>-3.950297</td>\n",
       "      <td>2.483015</td>\n",
       "      <td>-2.110721</td>\n",
       "      <td>-1.172979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.344352</td>\n",
       "      <td>0.441910</td>\n",
       "      <td>-0.655871</td>\n",
       "      <td>0.063072</td>\n",
       "      <td>-1.891197</td>\n",
       "      <td>-0.224493</td>\n",
       "      <td>-1.741030</td>\n",
       "      <td>0.773491</td>\n",
       "      <td>2.123364</td>\n",
       "      <td>1.707830</td>\n",
       "      <td>-3.144857</td>\n",
       "      <td>1.326751</td>\n",
       "      <td>-2.125668</td>\n",
       "      <td>0.281651</td>\n",
       "      <td>-1.305697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2.452951</td>\n",
       "      <td>-0.174916</td>\n",
       "      <td>1.877249</td>\n",
       "      <td>-0.442922</td>\n",
       "      <td>0.942239</td>\n",
       "      <td>-1.480626</td>\n",
       "      <td>-0.138366</td>\n",
       "      <td>2.849003</td>\n",
       "      <td>0.308466</td>\n",
       "      <td>-0.692214</td>\n",
       "      <td>0.693084</td>\n",
       "      <td>-3.875676</td>\n",
       "      <td>2.494982</td>\n",
       "      <td>-0.641738</td>\n",
       "      <td>-2.852213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-2.537599</td>\n",
       "      <td>0.363991</td>\n",
       "      <td>-4.153302</td>\n",
       "      <td>1.784039</td>\n",
       "      <td>-2.676023</td>\n",
       "      <td>4.545978</td>\n",
       "      <td>0.123587</td>\n",
       "      <td>-0.901131</td>\n",
       "      <td>2.163326</td>\n",
       "      <td>-2.637138</td>\n",
       "      <td>-0.808724</td>\n",
       "      <td>1.085521</td>\n",
       "      <td>1.152798</td>\n",
       "      <td>-2.617679</td>\n",
       "      <td>-5.516696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.394290  0.346584  2.283581 -1.559172  0.641352 -2.573262 -0.407517   \n",
       "1   1.442065  1.753741 -0.565542 -0.019844 -0.217345 -0.505208 -0.836395   \n",
       "2   0.158795 -2.018488  1.363381  0.369942 -0.553480 -0.829095  0.797979   \n",
       "3   1.180820 -0.302838  2.811929 -1.769756  1.171722 -4.010535 -0.339541   \n",
       "4  -0.535161 -1.304216  0.194147 -0.127602 -0.704615  1.089379 -0.192465   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -0.840972  0.419546 -0.149228 -2.066541 -1.074929 -2.850332  0.213039   \n",
       "96  1.944198 -0.182270  2.034609 -1.864585  2.520702 -3.416261 -1.658307   \n",
       "97 -0.344352  0.441910 -0.655871  0.063072 -1.891197 -0.224493 -1.741030   \n",
       "98  2.452951 -0.174916  1.877249 -0.442922  0.942239 -1.480626 -0.138366   \n",
       "99 -2.537599  0.363991 -4.153302  1.784039 -2.676023  4.545978  0.123587   \n",
       "\n",
       "           7         8         9        10        11        12        13  \\\n",
       "0   2.417698 -1.459789  3.592460 -4.019680  0.790601 -1.833108  3.480442   \n",
       "1   3.096807  0.408895 -0.085744 -0.584852 -2.247291  0.499501 -1.568848   \n",
       "2  -0.601401  3.293327 -1.130796  2.697072 -1.542107  5.722812 -1.352311   \n",
       "3   0.686395 -2.497994 -1.055499 -0.307648 -3.129533  2.950652  1.869410   \n",
       "4  -2.312792  1.273764  1.341614  0.833310  0.889260  0.310092 -0.762782   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -0.793650  1.961616 -0.598479  2.261300 -1.971938  4.682809 -3.231114   \n",
       "96  2.704336 -2.603829  0.000127  0.012510 -3.950297  2.483015 -2.110721   \n",
       "97  0.773491  2.123364  1.707830 -3.144857  1.326751 -2.125668  0.281651   \n",
       "98  2.849003  0.308466 -0.692214  0.693084 -3.875676  2.494982 -0.641738   \n",
       "99 -0.901131  2.163326 -2.637138 -0.808724  1.085521  1.152798 -2.617679   \n",
       "\n",
       "           14  \n",
       "0    6.263829  \n",
       "1   -1.472852  \n",
       "2  -10.048166  \n",
       "3    1.805169  \n",
       "4   -5.504899  \n",
       "..        ...  \n",
       "95  -8.642133  \n",
       "96  -1.172979  \n",
       "97  -1.305697  \n",
       "98  -2.852213  \n",
       "99  -5.516696  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf19d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_df)):\n",
    "    if i == 0:\n",
    "        con_df = pd.concat([data_df[i:i+1], empty_row])\n",
    "    else:\n",
    "        con_df2 = pd.concat([data_df[i:i+1], empty_row])\n",
    "        con_df = pd.concat([con_df, con_df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8cd29760",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "con_df.reset_index(drop= True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "132f5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_df.to_csv('./data/GAIN_200.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6bfb31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Packages\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_gpu = False  # set it to True to use GPU and False to use CPU\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7ba1a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% System Parameters\n",
    "# 1. Mini batch size\n",
    "mb_size = 128\n",
    "# 2. Missing rate\n",
    "p_miss = 0.5\n",
    "# 3. Hint rate\n",
    "p_hint = 0.9\n",
    "# 4. Loss Hyperparameters\n",
    "alpha = 10\n",
    "# 5. Train Rate\n",
    "train_rate = 0.8\n",
    "\n",
    "#%% Data\n",
    "\n",
    "# Data generation\n",
    "Data = con_df.values\n",
    "\n",
    "# Parameters\n",
    "No = len(Data)\n",
    "Dim = len(Data[0,:])\n",
    "\n",
    "# Hidden state dimensions\n",
    "H_Dim1 = Dim\n",
    "H_Dim2 = Dim\n",
    "\n",
    "# Normalization (0 to 1)\n",
    "Min_Val = np.zeros(Dim)\n",
    "Max_Val = np.zeros(Dim)\n",
    "\n",
    "for i in range(Dim):\n",
    "    Min_Val[i] = np.min(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] - np.min(Data[:,i])\n",
    "    Max_Val[i] = np.max(Data[:,i])\n",
    "    Data[:,i] = Data[:,i] / (np.max(Data[:,i]) + 1e-6)    \n",
    "\n",
    "#%% Missing introducing\n",
    "p_miss_vec = p_miss * np.ones((Dim,1)) \n",
    "   \n",
    "Missing = np.zeros((No,Dim))\n",
    "\n",
    "for i in range(Dim):\n",
    "    A = np.random.uniform(0., 1., size = [len(Data),])\n",
    "    B = A > p_miss_vec[i]\n",
    "    Missing[:,i] = 1.*B\n",
    "\n",
    "    \n",
    "#%% Train Test Division    \n",
    "   \n",
    "idx = np.random.permutation(No)\n",
    "\n",
    "Train_No = int(No * train_rate)\n",
    "Test_No = No - Train_No\n",
    "    \n",
    "# Train / Test Features\n",
    "trainX = Data[idx[:Train_No],:]\n",
    "testX = Data[idx[Train_No:],:]\n",
    "\n",
    "# Train / Test Missing Indicators\n",
    "trainM = Missing[idx[:Train_No],:]\n",
    "testM = Missing[idx[Train_No:],:]\n",
    "\n",
    "#%% Necessary Functions\n",
    "\n",
    "# 1. Xavier Initialization Definition\n",
    "# def xavier_init(size):\n",
    "#     in_dim = size[0]\n",
    "#     xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "#     return tf.random_normal(shape = size, stddev = xavier_stddev)\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return np.random.normal(size = size, scale = xavier_stddev)\n",
    "    \n",
    "# Hint Vector Generation\n",
    "def sample_M(m, n, p):\n",
    "    A = np.random.uniform(0., 1., size = [m, n])\n",
    "    B = A > p\n",
    "    C = 1.*B\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0bceb108",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentationX = Data\n",
    "augmentationM = np.zeros_like(Data)\n",
    "for i in range(Dim):\n",
    "    A = np.random.uniform(0., 1., size = [len(Data),])\n",
    "    B = A > p_miss_vec[i]\n",
    "    augmentationM[:,i] = 1.*B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9f477b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu is True:\n",
    "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Hint as inputs\n",
    "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
    "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")       # Output is multi-variate\n",
    "else:\n",
    "    D_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Hint as inputs\n",
    "    D_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
    "\n",
    "    D_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
    "    D_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
    "\n",
    "    D_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
    "    D_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)       # Output is multi-variate\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3]\n",
    "\n",
    "#%% 2. Generator\n",
    "if use_gpu is True:\n",
    "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True, device=\"cuda\")     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True, device=\"cuda\")\n",
    "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True, device=\"cuda\")\n",
    "else:\n",
    "    G_W1 = torch.tensor(xavier_init([Dim*2, H_Dim1]),requires_grad=True)     # Data + Mask as inputs (Random Noises are in Missing Components)\n",
    "    G_b1 = torch.tensor(np.zeros(shape = [H_Dim1]),requires_grad=True)\n",
    "\n",
    "    G_W2 = torch.tensor(xavier_init([H_Dim1, H_Dim2]),requires_grad=True)\n",
    "    G_b2 = torch.tensor(np.zeros(shape = [H_Dim2]),requires_grad=True)\n",
    "\n",
    "    G_W3 = torch.tensor(xavier_init([H_Dim2, Dim]),requires_grad=True)\n",
    "    G_b3 = torch.tensor(np.zeros(shape = [Dim]),requires_grad=True)\n",
    "theta_G = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1fc64af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 1. Generator\n",
    "def generator(new_x,m):\n",
    "    inputs = torch.cat(dim = 1, tensors = [new_x,m])  # Mask + Data Concatenate\n",
    "    G_h1 = F.relu(torch.matmul(inputs, G_W1) + G_b1)\n",
    "    G_h2 = F.relu(torch.matmul(G_h1, G_W2) + G_b2)   \n",
    "    G_prob = torch.sigmoid(torch.matmul(G_h2, G_W3) + G_b3) # [0,1] normalized Output\n",
    "    \n",
    "    return G_prob\n",
    "\n",
    "#%% 2. Discriminator\n",
    "def discriminator(new_x, h):\n",
    "    inputs = torch.cat(dim = 1, tensors = [new_x,h])  # Hint + Data Concatenate\n",
    "    D_h1 = F.relu(torch.matmul(inputs, D_W1) + D_b1)  \n",
    "    D_h2 = F.relu(torch.matmul(D_h1, D_W2) + D_b2)\n",
    "    D_logit = torch.matmul(D_h2, D_W3) + D_b3\n",
    "    D_prob = torch.sigmoid(D_logit)  # [0,1] Probability Output\n",
    "    \n",
    "    return D_prob\n",
    "\n",
    "#%% 3. Other functions\n",
    "# Random sample generator for Z\n",
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(0., 0.01, size = [m, n])        \n",
    "\n",
    "# Mini-batch generation\n",
    "def sample_idx(m, n):\n",
    "    A = np.random.permutation(m)\n",
    "    idx = A[:n]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "03f2054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(M, New_X, H):\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "    # Combine with original data\n",
    "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "\n",
    "    # Discriminator\n",
    "    D_prob = discriminator(Hat_New_X, H)\n",
    "\n",
    "    #%% Loss\n",
    "    D_loss = -torch.mean(M * torch.log(D_prob + 1e-8) + (1-M) * torch.log(1. - D_prob + 1e-8))\n",
    "    return D_loss\n",
    "\n",
    "def generator_loss(X, M, New_X, H):\n",
    "    #%% Structure\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "\n",
    "    # Combine with original data\n",
    "    Hat_New_X = New_X * M + G_sample * (1-M)\n",
    "\n",
    "    # Discriminator\n",
    "    D_prob = discriminator(Hat_New_X, H)\n",
    "\n",
    "    #%% Loss\n",
    "    G_loss1 = -torch.mean((1-M) * torch.log(D_prob + 1e-8))\n",
    "    MSE_train_loss = torch.mean((M * New_X - M * G_sample)**2) / torch.mean(M)\n",
    "\n",
    "    G_loss = G_loss1 + alpha * MSE_train_loss \n",
    "\n",
    "    #%% MSE Performance metric\n",
    "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
    "    return G_loss, MSE_train_loss, MSE_test_loss\n",
    "    \n",
    "def test_loss(X, M, New_X):\n",
    "    #%% Structure\n",
    "    # Generator\n",
    "    G_sample = generator(New_X,M)\n",
    "\n",
    "    #%% MSE Performance metric\n",
    "    MSE_test_loss = torch.mean(((1-M) * X - (1-M)*G_sample)**2) / torch.mean(1-M)\n",
    "    return MSE_test_loss, G_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8c4669cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_D = torch.optim.Adam(params=theta_D)\n",
    "optimizer_G = torch.optim.Adam(params=theta_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f964e9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                           | 26/500 [00:00<00:01, 247.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Train_loss: 0.3039\n",
      "Test_loss: 0.289\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████▍                                                          | 129/500 [00:00<00:01, 210.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Train_loss: 0.1466\n",
      "Test_loss: 0.1695\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████▊                                         | 239/500 [00:01<00:01, 202.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "Train_loss: 0.1336\n",
      "Test_loss: 0.1558\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████████████████████████████████████████████████▍                            | 319/500 [00:01<00:01, 166.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 300\n",
      "Train_loss: 0.1187\n",
      "Test_loss: 0.1538\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████████████████▌             | 415/500 [00:02<00:00, 138.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 400\n",
      "Train_loss: 0.1174\n",
      "Test_loss: 0.1653\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 500/500 [00:02<00:00, 172.05it/s]\n"
     ]
    }
   ],
   "source": [
    "#%% Start Iterations\n",
    "for it in tqdm(range(500)):    \n",
    "    \n",
    "    #%% Inputs\n",
    "    mb_idx = sample_idx(Train_No, mb_size)\n",
    "    X_mb = trainX[mb_idx,:]  \n",
    "    \n",
    "    Z_mb = sample_Z(mb_size, Dim) \n",
    "    M_mb = trainM[mb_idx,:]  \n",
    "    H_mb1 = sample_M(mb_size, Dim, 1-p_hint)\n",
    "    H_mb = M_mb * H_mb1\n",
    "    \n",
    "    New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "    \n",
    "    if use_gpu is True:\n",
    "        X_mb = torch.tensor(X_mb, device=\"cuda\")\n",
    "        M_mb = torch.tensor(M_mb, device=\"cuda\")\n",
    "        H_mb = torch.tensor(H_mb, device=\"cuda\")\n",
    "        New_X_mb = torch.tensor(New_X_mb, device=\"cuda\")\n",
    "    else:\n",
    "        X_mb = torch.tensor(X_mb)\n",
    "        M_mb = torch.tensor(M_mb)\n",
    "        H_mb = torch.tensor(H_mb)\n",
    "        New_X_mb = torch.tensor(New_X_mb)\n",
    "    \n",
    "    optimizer_D.zero_grad()\n",
    "    D_loss_curr = discriminator_loss(M=M_mb, New_X=New_X_mb, H=H_mb)\n",
    "    D_loss_curr.backward()\n",
    "    optimizer_D.step()\n",
    "    \n",
    "    optimizer_G.zero_grad()\n",
    "    G_loss_curr, MSE_train_loss_curr, MSE_test_loss_curr = generator_loss(X=X_mb, M=M_mb, New_X=New_X_mb, H=H_mb)\n",
    "    G_loss_curr.backward()\n",
    "    optimizer_G.step()    \n",
    "        \n",
    "    #%% Intermediate Losses\n",
    "    if it % 100 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('Train_loss: {:.4}'.format(np.sqrt(MSE_train_loss_curr.item())))\n",
    "        print('Test_loss: {:.4}'.format(np.sqrt(MSE_test_loss_curr.item())))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7e32eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentationX = Data\n",
    "augmentationM = np.zeros_like(Data)\n",
    "for i in range(Dim):\n",
    "    A = np.random.uniform(0., 1., size = [len(Data),])\n",
    "    B = A > p_miss_vec[i]\n",
    "    augmentationM[:,i] = 1.*B\n",
    "Z_mb = sample_Z(200, 15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "373dc132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z_mb = sample_Z(Test_No, Dim) \n",
    "M_mb = augmentationM\n",
    "X_mb = augmentationX\n",
    "        \n",
    "New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n",
    "\n",
    "if use_gpu is True:\n",
    "    X_mb = torch.tensor(X_mb, device='cuda')\n",
    "    M_mb = torch.tensor(M_mb, device='cuda')\n",
    "    New_X_mb = torch.tensor(New_X_mb, device='cuda')\n",
    "else:\n",
    "    X_mb = torch.tensor(X_mb)\n",
    "    M_mb = torch.tensor(M_mb)\n",
    "    New_X_mb = torch.tensor(New_X_mb)\n",
    "    \n",
    "MSE_final, Sample = test_loss(X=X_mb, M=M_mb, New_X=New_X_mb)\n",
    "# np.set_printoptions(formatter={'float': lambda x: \"{0:0.8f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2cdc774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data = M_mb * X_mb + (1-M_mb) * Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5d7253fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df = pd.DataFrame(imputed_data.detach().numpy(), columns = con_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6af355b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df.to_csv('./data/augmentation_linear_200.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f17507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
