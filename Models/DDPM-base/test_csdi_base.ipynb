{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "def Conv1d_with_init(in_channels, out_channels, kernel_size):\n",
    "    layer = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "    nn.init.kaiming_normal_(layer.weight)\n",
    "    return layer\n",
    "\n",
    "def get_torch_trans(heads=8, layers=1, channels=64):\n",
    "    encoder_layer = nn.TransformerEncoderLayer(\n",
    "        d_model=channels, nhead=heads, dim_feedforward=64, activation=\"gelu\"\n",
    "    )\n",
    "    return nn.TransformerEncoder(encoder_layer, num_layers=layers)\n",
    "\n",
    "class DiffusionEmbedding(nn.Module):\n",
    "    def __init__(self, num_steps, embedding_dim=128, projection_dim=None):\n",
    "        super().__init__()\n",
    "        if projection_dim is None:\n",
    "            projection_dim = embedding_dim\n",
    "        self.register_buffer(\n",
    "            \"embedding\",\n",
    "            self._build_embedding(num_steps, embedding_dim / 2),\n",
    "            persistent=False,\n",
    "        )\n",
    "        self.projection1 = nn.Linear(embedding_dim, projection_dim)\n",
    "        self.projection2 = nn.Linear(projection_dim, projection_dim)\n",
    "\n",
    "    def forward(self, diffusion_step):\n",
    "        x = self.embedding[diffusion_step]\n",
    "        x = self.projection1(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.projection2(x)\n",
    "        x = F.silu(x)\n",
    "        return x\n",
    "\n",
    "    def _build_embedding(self, num_steps, dim=64):\n",
    "        steps = torch.arange(num_steps).unsqueeze(1)\n",
    "        frequencies = 10.0 ** (torch.arange(dim) / (dim - 1) * 4.0).unsqueeze(0)\n",
    "        table = steps * frequencies\n",
    "        table = torch.cat([torch.sin(table), torch.cos(table)], dim=1)\n",
    "        return table\n",
    "    \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, diffusion_embedding_dim, nheads):\n",
    "        super().__init__()\n",
    "        self.diffusion_projection = nn.Linear(diffusion_embedding_dim, channels)\n",
    "        self.mid_projection = Conv1d_with_init(channels, 2 * channels, 1)\n",
    "        self.output_projection = Conv1d_with_init(channels, 2 * channels, 1)\n",
    "\n",
    "        self.time_layer = get_torch_trans(heads=nheads, layers=1, channels=channels)\n",
    "        self.feature_layer = get_torch_trans(heads=nheads, layers=1, channels=channels)\n",
    "\n",
    "    def forward_time(self, y, base_shape):\n",
    "        B, channel, K, L = base_shape\n",
    "        if L == 1:\n",
    "            return y\n",
    "        y = y.reshape(B, channel, K, L).permute(0, 2, 1, 3).reshape(B * K, channel, L)\n",
    "        y = self.time_layer(y.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        y = y.reshape(B, K, channel, L).permute(0, 2, 1, 3).reshape(B, channel, K * L)\n",
    "        return y\n",
    "\n",
    "    def forward_feature(self, y, base_shape):\n",
    "        B, channel, K, L = base_shape\n",
    "        if K == 1:\n",
    "            return y\n",
    "        y = y.reshape(B, channel, K, L).permute(0, 3, 1, 2).reshape(B * L, channel, K)\n",
    "        y = self.feature_layer(y.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        y = y.reshape(B, L, channel, K).permute(0, 2, 3, 1).reshape(B, channel, K * L)\n",
    "        return y\n",
    "\n",
    "    def forward(self, x, diffusion_emb):\n",
    "        B, channel, K, L = x.shape\n",
    "        base_shape = x.shape\n",
    "        x = x.reshape(B, channel, K * L)\n",
    "\n",
    "        diffusion_emb = self.diffusion_projection(diffusion_emb).unsqueeze(-1)\n",
    "        y = x + diffusion_emb\n",
    "\n",
    "        y = self.forward_time(y, base_shape)\n",
    "        y = self.forward_feature(y, base_shape)\n",
    "        y = self.mid_projection(y)\n",
    "        \n",
    "        gate, filter = torch.chunk(y, 2, dim=1)\n",
    "        y = torch.sigmoid(gate) * torch.tanh(filter)\n",
    "        y = self.output_projection(y)\n",
    "\n",
    "        residual, skip = torch.chunk(y, 2, dim=1)\n",
    "        x = x.reshape(base_shape)\n",
    "        residual = residual.reshape(base_shape)\n",
    "        skip = skip.reshape(base_shape)\n",
    "        return (x + residual) / math.sqrt(2.0), skip\n",
    "    \n",
    "class diff_CSDI(nn.Module):\n",
    "    def __init__(self, config, inputdim=2):\n",
    "        super().__init__()\n",
    "        self.channels = config[\"channels\"]\n",
    "\n",
    "        self.diffusion_embedding = DiffusionEmbedding(\n",
    "            num_steps=config[\"num_steps\"],\n",
    "            embedding_dim=config[\"diffusion_embedding_dim\"],\n",
    "        )\n",
    "\n",
    "        self.input_projection = Conv1d_with_init(inputdim, self.channels, 1)\n",
    "        self.output_projection1 = Conv1d_with_init(self.channels, self.channels, 1)\n",
    "        self.output_projection2 = Conv1d_with_init(self.channels, 1, 1)\n",
    "        nn.init.zeros_(self.output_projection2.weight)\n",
    "\n",
    "        self.residual_layers = nn.ModuleList(\n",
    "            [\n",
    "                ResidualBlock(\n",
    "                    channels=self.channels,\n",
    "                    diffusion_embedding_dim=config[\"diffusion_embedding_dim\"],\n",
    "                    nheads=config[\"nheads\"],\n",
    "                )\n",
    "                for _ in range(config[\"layers\"])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, diffusion_step):\n",
    "        B, inputdim, K, L = x.shape\n",
    "\n",
    "        x = x.reshape(B, inputdim, K * L)\n",
    "        x = self.input_projection(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.reshape(B, self.channels, K, L)\n",
    "\n",
    "        diffusion_emb = self.diffusion_embedding(diffusion_step)\n",
    "\n",
    "        skip = []\n",
    "        for layer in self.residual_layers:\n",
    "            x, skip_connection = layer(x, diffusion_emb)\n",
    "            skip.append(skip_connection)\n",
    "\n",
    "        x = torch.sum(torch.stack(skip), dim=0) / math.sqrt(len(self.residual_layers))\n",
    "        x = x.reshape(B, self.channels, K * L)\n",
    "        x = self.output_projection1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.output_projection2(x)\n",
    "        x = x.reshape(B, K, L)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSDI_base(nn.Module):\n",
    "    def __init__(self, target_dim, config, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.target_dim = target_dim\n",
    "\n",
    "        self.emb_time_dim = config[\"model\"][\"timeemb\"]\n",
    "        self.emb_feature_dim = config[\"model\"][\"featureemb\"]\n",
    "        self.is_unconditional = config[\"model\"][\"is_unconditional\"]\n",
    "        self.target_strategy = config[\"model\"][\"target_strategy\"]\n",
    "\n",
    "        self.emb_total_dim = self.emb_time_dim + self.emb_feature_dim\n",
    "        if self.is_unconditional == False:\n",
    "            self.emb_total_dim += 1  # for conditional mask\n",
    "        self.embed_layer = nn.Embedding(\n",
    "            num_embeddings=self.target_dim, embedding_dim=self.emb_feature_dim\n",
    "        )\n",
    "\n",
    "        config_diff = config[\"diffusion\"]\n",
    "        config_diff[\"side_dim\"] = self.emb_total_dim\n",
    "\n",
    "        input_dim = 1 if self.is_unconditional == True else 2\n",
    "        self.diffmodel = diff_CSDI(config_diff, input_dim)\n",
    "\n",
    "        # parameters for diffusion models\n",
    "        self.num_steps = config_diff[\"num_steps\"]\n",
    "        if config_diff[\"schedule\"] == \"quad\":\n",
    "            self.beta = np.linspace(\n",
    "                config_diff[\"beta_start\"] ** 0.5, config_diff[\"beta_end\"] ** 0.5, self.num_steps\n",
    "            ) ** 2\n",
    "        elif config_diff[\"schedule\"] == \"linear\":\n",
    "            self.beta = np.linspace(\n",
    "                config_diff[\"beta_start\"], config_diff[\"beta_end\"], self.num_steps\n",
    "            )\n",
    "\n",
    "        self.alpha_hat = 1 - self.beta\n",
    "        self.alpha = np.cumprod(self.alpha_hat)\n",
    "        self.alpha_torch = torch.tensor(self.alpha).float().to(self.device).unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "    def time_embedding(self, pos, d_model=128):\n",
    "        pe = torch.zeros(pos.shape[0], pos.shape[1], d_model).to(self.device)\n",
    "        position = pos.unsqueeze(2)\n",
    "        div_term = 1 / torch.pow(\n",
    "            10000.0, torch.arange(0, d_model, 2).to(self.device) / d_model\n",
    "        )\n",
    "        pe[:, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, :, 1::2] = torch.cos(position * div_term)\n",
    "        return pe\n",
    "\n",
    "    def get_randmask(self, observed_mask):\n",
    "        rand_for_mask = torch.rand_like(observed_mask) * observed_mask\n",
    "        rand_for_mask = rand_for_mask.reshape(len(rand_for_mask), -1)\n",
    "        for i in range(len(observed_mask)):\n",
    "            sample_ratio = np.random.rand()  # missing ratio\n",
    "            num_observed = observed_mask[i].sum().item()\n",
    "            num_masked = round(num_observed * sample_ratio)\n",
    "            rand_for_mask[i][rand_for_mask[i].topk(num_masked).indices] = -1\n",
    "        cond_mask = (rand_for_mask > 0).reshape(observed_mask.shape).float()\n",
    "        return cond_mask\n",
    "\n",
    "    def get_hist_mask(self, observed_mask, for_pattern_mask=None):\n",
    "        if for_pattern_mask is None:\n",
    "            for_pattern_mask = observed_mask\n",
    "        if self.target_strategy == \"mix\":\n",
    "            rand_mask = self.get_randmask(observed_mask)\n",
    "\n",
    "        cond_mask = observed_mask.clone()\n",
    "        for i in range(len(cond_mask)):\n",
    "            mask_choice = np.random.rand()\n",
    "            if self.target_strategy == \"mix\" and mask_choice > 0.5:\n",
    "                cond_mask[i] = rand_mask[i]\n",
    "            else:  # draw another sample for histmask (i-1 corresponds to another sample)\n",
    "                cond_mask[i] = cond_mask[i] * for_pattern_mask[i - 1] \n",
    "        return cond_mask\n",
    "\n",
    "    def get_side_info(self, observed_tp, cond_mask):\n",
    "        B, K, L = cond_mask.shape\n",
    "\n",
    "        time_embed = self.time_embedding(observed_tp, self.emb_time_dim)  # (B,L,emb)\n",
    "        time_embed = time_embed.unsqueeze(2).expand(-1, -1, K, -1)\n",
    "        feature_embed = self.embed_layer(\n",
    "            torch.arange(self.target_dim).to(self.device)\n",
    "        )  # (K,emb)\n",
    "        feature_embed = feature_embed.unsqueeze(0).unsqueeze(0).expand(B, L, -1, -1)\n",
    "\n",
    "        side_info = torch.cat([time_embed, feature_embed], dim=-1)  # (B,L,K,*)\n",
    "        side_info = side_info.permute(0, 3, 2, 1)  # (B,*,K,L)\n",
    "\n",
    "        if self.is_unconditional == False:\n",
    "            side_mask = cond_mask.unsqueeze(1)  # (B,1,K,L)\n",
    "            side_info = torch.cat([side_info, side_mask], dim=1)\n",
    "\n",
    "        return side_info\n",
    "\n",
    "    def calc_loss_valid(\n",
    "        self, observed_data, cond_mask, observed_mask, side_info, is_train\n",
    "    ):\n",
    "        loss_sum = 0\n",
    "        for t in range(self.num_steps):  # calculate loss for all t\n",
    "            loss = self.calc_loss(\n",
    "                observed_data, cond_mask, observed_mask, side_info, is_train, set_t=t\n",
    "            )\n",
    "            loss_sum += loss.detach()\n",
    "        return loss_sum / self.num_steps\n",
    "\n",
    "    def calc_loss(\n",
    "        self, observed_data, cond_mask, observed_mask, side_info, is_train, set_t=-1\n",
    "    ):\n",
    "        B, K, L = observed_data.shape\n",
    "        if is_train != 1:  # for validation\n",
    "            t = (torch.ones(B) * set_t).long().to(self.device)\n",
    "        else:\n",
    "            t = torch.randint(0, self.num_steps, [B]).to(self.device)\n",
    "        current_alpha = self.alpha_torch[t]  # (B,1,1)\n",
    "        noise = torch.randn_like(observed_data)\n",
    "        noisy_data = (current_alpha ** 0.5) * observed_data + (1.0 - current_alpha) ** 0.5 * noise\n",
    "\n",
    "        total_input = self.set_input_to_diffmodel(noisy_data, observed_data, cond_mask)\n",
    "\n",
    "        predicted = self.diffmodel(total_input, side_info, t)  # (B,K,L)\n",
    "\n",
    "        target_mask = observed_mask - cond_mask\n",
    "        residual = (noise - predicted) * target_mask\n",
    "        num_eval = target_mask.sum()\n",
    "        loss = (residual ** 2).sum() / (num_eval if num_eval > 0 else 1)\n",
    "        return loss\n",
    "\n",
    "    def set_input_to_diffmodel(self, noisy_data, observed_data, cond_mask):\n",
    "        if self.is_unconditional == True:\n",
    "            total_input = noisy_data.unsqueeze(1)  # (B,1,K,L)\n",
    "        else:\n",
    "            cond_obs = (cond_mask * observed_data).unsqueeze(1)\n",
    "            noisy_target = ((1 - cond_mask) * noisy_data).unsqueeze(1)\n",
    "            total_input = torch.cat([cond_obs, noisy_target], dim=1)  # (B,2,K,L)\n",
    "\n",
    "        return total_input\n",
    "\n",
    "    def impute(self, observed_data, cond_mask, side_info, n_samples):\n",
    "        B, K, L = observed_data.shape\n",
    "\n",
    "        imputed_samples = torch.zeros(B, n_samples, K, L).to(self.device)\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            # generate noisy observation for unconditional model\n",
    "            if self.is_unconditional == True:\n",
    "                noisy_obs = observed_data\n",
    "                noisy_cond_history = []\n",
    "                for t in range(self.num_steps):\n",
    "                    noise = torch.randn_like(noisy_obs)\n",
    "                    noisy_obs = (self.alpha_hat[t] ** 0.5) * noisy_obs + self.beta[t] ** 0.5 * noise\n",
    "                    noisy_cond_history.append(noisy_obs * cond_mask)\n",
    "\n",
    "            current_sample = torch.randn_like(observed_data)\n",
    "\n",
    "            for t in range(self.num_steps - 1, -1, -1):\n",
    "                if self.is_unconditional == True:\n",
    "                    diff_input = cond_mask * noisy_cond_history[t] + (1.0 - cond_mask) * current_sample\n",
    "                    diff_input = diff_input.unsqueeze(1)  # (B,1,K,L)\n",
    "                else:\n",
    "                    cond_obs = (cond_mask * observed_data).unsqueeze(1)\n",
    "                    noisy_target = ((1 - cond_mask) * current_sample).unsqueeze(1)\n",
    "                    diff_input = torch.cat([cond_obs, noisy_target], dim=1)  # (B,2,K,L)\n",
    "                predicted = self.diffmodel(diff_input, side_info, torch.tensor([t]).to(self.device))\n",
    "\n",
    "                coeff1 = 1 / self.alpha_hat[t] ** 0.5\n",
    "                coeff2 = (1 - self.alpha_hat[t]) / (1 - self.alpha[t]) ** 0.5\n",
    "                current_sample = coeff1 * (current_sample - coeff2 * predicted)\n",
    "\n",
    "                if t > 0:\n",
    "                    noise = torch.randn_like(current_sample)\n",
    "                    sigma = (\n",
    "                        (1.0 - self.alpha[t - 1]) / (1.0 - self.alpha[t]) * self.beta[t]\n",
    "                    ) ** 0.5\n",
    "                    current_sample += sigma * noise\n",
    "\n",
    "            imputed_samples[:, i] = current_sample.detach()\n",
    "        return imputed_samples\n",
    "\n",
    "    def forward(self, batch, is_train=1):\n",
    "        (\n",
    "            observed_data,\n",
    "            observed_mask,\n",
    "            observed_tp,\n",
    "            gt_data,\n",
    "            gt_mask,\n",
    "            for_pattern_mask,\n",
    "            _,\n",
    "        ) = self.process_data(batch)\n",
    "        if is_train == 0:\n",
    "            cond_mask = gt_mask\n",
    "        elif self.target_strategy != \"random\":\n",
    "            cond_mask = self.get_hist_mask(\n",
    "                observed_mask, for_pattern_mask=for_pattern_mask\n",
    "            )\n",
    "        else:\n",
    "            cond_mask = self.get_randmask(observed_mask)\n",
    "\n",
    "        side_info = self.get_side_info(observed_tp, cond_mask)\n",
    "\n",
    "        loss_func = self.calc_loss if is_train == 1 else self.calc_loss_valid\n",
    "\n",
    "        return loss_func(observed_data, cond_mask, observed_mask, side_info, is_train)\n",
    "\n",
    "    def evaluate(self, batch, n_samples):\n",
    "        (\n",
    "            observed_data,\n",
    "            observed_mask,\n",
    "            observed_tp,\n",
    "            gt_data,\n",
    "            gt_mask,\n",
    "            _,\n",
    "            cut_length,\n",
    "        ) = self.process_data(batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            cond_mask = gt_mask\n",
    "            target_mask = cond_mask - observed_mask\n",
    "            print(torch.sum(cond_mask))\n",
    "            print(torch.sum(observed_mask))\n",
    "            print(torch.sum(target_mask))\n",
    "\n",
    "            side_info = self.get_side_info(observed_tp, cond_mask)\n",
    "\n",
    "            samples = self.impute(observed_data, cond_mask, side_info, n_samples)\n",
    "\n",
    "            for i in range(len(cut_length)):  # to avoid double evaluation\n",
    "                target_mask[i, ..., 0 : cut_length[i].item()] = 0\n",
    "            print(torch.sum(target_mask))\n",
    "        return samples, gt_data, target_mask, observed_mask, observed_tp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coolingts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
