{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chanyoung\\anaconda3\\envs\\coolingts\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "# from algoritm.diffstg.graph_algo import *\n",
    "\n",
    "def TimeEmbedding(timesteps: torch.Tensor, embedding_dim: int):\n",
    "    \"\"\"\n",
    "    This matches the implementation in Denoising Diffusion Probabilistic Models:\n",
    "    From Fairseq.\n",
    "    Build sinusoidal embeddings.\n",
    "    This matches the implementation in tensor2tensor, but differs slightly\n",
    "    from the description in Section 3.5 of \"Attention Is All You Need\".\n",
    "    \"\"\"\n",
    "    assert len(timesteps.shape) == 1\n",
    "\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
    "    emb = emb.to(device=timesteps.device)\n",
    "    emb = timesteps.float()[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    if embedding_dim % 2 == 1:  # zero pad\n",
    "        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialBlock(nn.Module):\n",
    "    def __init__(self, ks, c_in, c_out):\n",
    "        super(SpatialBlock, self).__init__()\n",
    "        self.theta = nn.Parameter(torch.FloatTensor(c_in, c_out, ks))\n",
    "        self.b = nn.Parameter(torch.FloatTensor(1, c_out, 1, 1))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.kaiming_uniform_(self.theta, a=math.sqrt(5))\n",
    "        fan_in, _ = init._calculate_fan_in_and_fan_out(self.theta)\n",
    "        bound = 1 / math.sqrt(fan_in)\n",
    "        init.uniform_(self.b, -bound, bound)\n",
    "\n",
    "    def forward(self, x, Lk):\n",
    "        # x: [b, c_in, time, n_nodes]\n",
    "        # Lk: [3, n_nodes, n_nodes]\n",
    "        if len(Lk.shape) == 2: # if supports_len == 1:\n",
    "            Lk=Lk.unsqueeze(0)\n",
    "        x_c = torch.einsum(\"knm,bitm->bitkn\", Lk, x)\n",
    "        x_gc = torch.einsum(\"iok,bitkn->botn\", self.theta,\n",
    "                            x_c) + self.b  # [b, c_out, time, n_nodes]\n",
    "        return torch.relu(x_gc + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chomp(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super().__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :, : -self.chomp_size]\n",
    "\n",
    "\n",
    "class TcnBlock(nn.Module):\n",
    "    def __init__(self, c_in, c_out, kernel_size, dilation_size=1, droupout=0.0):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation_size = dilation_size\n",
    "        self.padding = (self.kernel_size - 1) * self.dilation_size\n",
    "\n",
    "        self.conv = nn.Conv2d(c_in, c_out, kernel_size=(3, self.kernel_size), padding=(1, self.padding), dilation=(1, self.dilation_size))\n",
    "\n",
    "        self.chomp = Chomp(self.padding)\n",
    "        self.drop =  nn.Dropout(droupout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv, self.chomp, self.drop)\n",
    "\n",
    "        self.shortcut = nn.Conv2d(c_in, c_out, kernel_size=(1, 1)) if c_in != c_out else None\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C_in, V, T) -> (B, C_out, V, T)\n",
    "        out = self.net(x)\n",
    "        x_skip = x if self.shortcut is None else self.shortcut(x)\n",
    "\n",
    "        return out + x_skip\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, c_in, c_out, config, kernel_size=3):\n",
    "        \"\"\"\n",
    "        :param c_in: in channels\n",
    "        :param c_out: out channels\n",
    "        :param kernel_size:\n",
    "        TCN convolution\n",
    "            input: (B, c_in, V, T)\n",
    "            output:(B, c_out, V, T)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.tcn1 = TcnBlock(c_in, c_out, kernel_size=kernel_size)\n",
    "        self.tcn2 = TcnBlock(c_out, c_out, kernel_size=kernel_size)\n",
    "        self.shortcut = nn.Identity() if c_in == c_out else nn.Conv2d(c_in, c_out, (1,1))\n",
    "        self.t_conv = nn.Conv2d(config.d_h, c_out, (1,1))\n",
    "        self.spatial = SpatialBlock(config.supports_len, c_out, c_out)\n",
    "\n",
    "        self.norm = nn.LayerNorm([config.V, c_out])\n",
    "    def forward(self, x, t, A_hat):\n",
    "        # x: (B, c_in, V, T), return (B, c_out, V, T)\n",
    "\n",
    "        h = self.tcn1(x)\n",
    "\n",
    "        h += self.t_conv(t[:, :, None, None])\n",
    "\n",
    "        h = self.tcn2(h)\n",
    "\n",
    "        h = self.norm(h.transpose(1,3)).transpose(1,3) # (B, c_out, V, T)\n",
    "\n",
    "        h = h.transpose(2,3) #(B, c_out, V, T)\n",
    "        h = self.spatial(h, A_hat).transpose(2,3) # (B, c_out, V, T)\n",
    "        return h + self.shortcut(x)\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, c_in, c_out, config):\n",
    "        \"\"\"\n",
    "        :param c_in: in channels, out channels\n",
    "        :param c_out:\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.res = ResidualBlock(c_in, c_out, config, kernel_size=3)\n",
    "\n",
    "    def forward(self, x, t, supports):\n",
    "        # x: (B, c_in, V, T), return (B, c_out, V, T)\n",
    "\n",
    "        return self.res(x, t, supports)\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, c_in):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c_in, c_in,  kernel_size= (1,3), stride=(1,2), padding=(0,1))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor, supports):\n",
    "        _ = t\n",
    "        _ = supports\n",
    "        return self.conv(x)\n",
    "\n",
    "class  UpBlock(nn.Module):\n",
    "    def __init__(self, c_in, c_out, config):\n",
    "        super().__init__()\n",
    "        self.res = ResidualBlock(c_in + c_out, c_out, config, kernel_size=3)\n",
    "\n",
    "    def forward(self, x, t, supports):\n",
    "        return self.res(x, t, supports)\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, c_in):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose2d(c_in, c_in, (1, 4), (1, 2), (0, 1))\n",
    "\n",
    "    def forward(self, x, t, supports):\n",
    "        _ = t\n",
    "        _ = supports\n",
    "        return  self.conv(x)\n",
    "\n",
    "class MiddleBlock(nn.Module):\n",
    "    def __init__(self, c_in, config):\n",
    "        super().__init__()\n",
    "        self.res1 = ResidualBlock(c_in, c_in, config, kernel_size=3)\n",
    "        self.res2 = ResidualBlock(c_in, c_in, config, kernel_size=3)\n",
    "\n",
    "    def forward(self, x, t, supports):\n",
    "        x = self.res1(x, t, supports)\n",
    "\n",
    "        x = self.res2(x, t, supports)\n",
    "\n",
    "        return x\n",
    "\n",
    "class UGnet(nn.Module):\n",
    "    def __init__(self, config) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        d_h = self.d_h = config.d_h\n",
    "        self.T_p = config.T_p\n",
    "        self.T_h = config.T_h\n",
    "        self.mem_num = self.config.mem_num  # 추가\n",
    "        # self.a1 = torch.rand\n",
    "\n",
    "         # project memory to embedding\n",
    "        self.We1 = nn.Parameter(torch.randn(self.config.data.num_vertices, self.mem_num), requires_grad = True) # 추가\n",
    "        self.We2 = nn.Parameter(torch.randn(self.config.data.num_vertices, self.mem_num), requires_grad = True) # 추가\n",
    "        self.Memory = nn.Parameter(torch.randn(self.mem_num, self.mem_num), requires_grad = True) # 추가\n",
    "        self.Wq = nn.Parameter(torch.randn(self.rnn_units, self.mem_dim), requires_grad=True) # 수정 예정 \n",
    "        T = self.T_p + self.T_h\n",
    "        self.F = config.F\n",
    "\n",
    "        self.n_blocks = config.get('n_blocks', 2)\n",
    "\n",
    "        # number of resolutions\n",
    "        n_resolutions = len(config.channel_multipliers)\n",
    "\n",
    "        # first half of U-Net = decreasing resolution\n",
    "        down = []\n",
    "        # number of channels\n",
    "        out_channels = in_channels = self.d_h\n",
    "        for i in range(n_resolutions):\n",
    "            out_channels = in_channels * config.channel_multipliers[i]\n",
    "            for _ in range(self.n_blocks):\n",
    "                down.append(DownBlock(in_channels, out_channels, config))\n",
    "                in_channels = out_channels\n",
    "\n",
    "            # down sample at all resolution except the last\n",
    "            if i < n_resolutions - 1:\n",
    "                down.append(Downsample(in_channels))\n",
    "\n",
    "        self.down = nn.ModuleList(down)\n",
    "\n",
    "        self.middle = MiddleBlock(out_channels, config)\n",
    "\n",
    "        # #### Second half of U-Net - increasing resolution\n",
    "        up = []\n",
    "        in_channels = out_channels\n",
    "        for i in reversed(range(n_resolutions)):\n",
    "            out_channels = in_channels\n",
    "            for _ in range(self.n_blocks):\n",
    "                up.append(UpBlock(in_channels, out_channels, config))\n",
    "\n",
    "            out_channels = in_channels // config.channel_multipliers[i]\n",
    "            up.append(UpBlock(in_channels, out_channels, config))\n",
    "            in_channels = out_channels\n",
    "            # up sample at all resolution except last\n",
    "            if i > 0:\n",
    "                up.append(Upsample(in_channels))\n",
    "\n",
    "        self.up = nn.ModuleList(up)\n",
    "\n",
    "        self.x_proj = nn.Conv2d(self.F, self.d_h, (1,1))\n",
    "        self.out = nn.Sequential(nn.Conv2d(self.d_h, self.F, (1,1)),\n",
    "                                 nn.Linear(2 * T, T),)\n",
    "        # for gcn\n",
    "        '''\n",
    "        a1 = asym_adj(config.A)\n",
    "        a2 = asym_adj(np.transpose(config.A))\n",
    "        self.a1 = torch.from_numpy(a1).to(config.device)\n",
    "        self.a2 = torch.from_numpy(a2).to(config.device)\n",
    "        config.supports_len = 2\n",
    "        '''\n",
    "        # for graph learning\n",
    "        node_embeddings1 = torch.matmul(self.We1, self.Memory)\n",
    "        node_embeddings2 = torch.matmul(self.We2, self.Memory)\n",
    "        self.a1 = F.softmax(F.relu(torch.mm(node_embeddings1, node_embeddings2.T)), dim=-1)\n",
    "        self.a2 = F.softmax(F.relu(torch.mm(node_embeddings2, node_embeddings1.T)), dim=-1)\n",
    "\n",
    "    # for attention \n",
    "    def query_memory(self, h_t: torch.Tensor): # 수정 예정 주어진 모델의 rnn 구조를 보고 h_t 차원 등 수정해야됨\n",
    "        query = torch.matmul(h_t, self.Wq)\n",
    "        att_score = torch.softmax(torch.matmul(query, self.Memory.t()), dim=-1)  # alpha: (B, N, M)\n",
    "        value = torch.matmul(att_score, self.Memory)\n",
    "        \n",
    "        return value, query\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor, c):\n",
    "        \"\"\"\n",
    "        :param x: x_t of current diffusion step, (B, F, V, T)\n",
    "        :param t: diffsusion step\n",
    "        :param c: condition information\n",
    "            used information in c:\n",
    "                x_masked: (B, F, V, T)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        x_masked, pos_w, pos_d = c  # x_masked: (B, F, V, T), pos_w: (B,T,1,1), pos_d: (B,T,1,1)\n",
    "\n",
    "        x = torch.cat((x, x_masked), dim=3) # (B, F, V, 2 * T)\n",
    "\n",
    "        x = self.x_proj(x)\n",
    "\n",
    "        t = TimeEmbedding(t, self.d_h)\n",
    "\n",
    "        h = [x]\n",
    "\n",
    "        supports = torch.stack([self.a1, self.a2])\n",
    "        \n",
    "        for m in self.down:\n",
    "            x = m(x, t, supports) # 이걸 encoder 라 생각하면\n",
    "            h.append(x)\n",
    "\n",
    "        # x = self.middle(x, t, supports)  # 삭제\n",
    "        out = []\n",
    "        h_att, _ = self.query_memory(h)\n",
    "        h_t = torch.cat([h, h_att], dim =1)\n",
    "        ht_list = [h_t] * len(self.up)\n",
    "        for t in range(self.config.horizon):\n",
    "            for i, m in enumerate(self.up):\n",
    "                #if isinstance(m,  Upsample): # 삭제\n",
    "                #    x = m(x, t, supports)    # 삭제\n",
    "                #else:                        # 삭제\n",
    "                s = ht_list[i].pop()\n",
    "                x = torch.cat((x, s), dim=1)\n",
    "                x = m(x,t, supports)\n",
    "            out.append(self.out(x))\n",
    "\n",
    "            # e = self.out(x)\n",
    "        output = torch.stack(out, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = [0,125,124,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 125\n",
      "2 124\n",
      "3 12\n"
     ]
    }
   ],
   "source": [
    "for i, _ in enumerate(aaa):\n",
    "    print(i, _)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coolingts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
